{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51b9924-03ec-4026-a678-041c2da7e6df",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d768fa-ef76-4420-ba49-199eedb0a04f",
   "metadata": {},
   "source": [
    "# Exercise: Apply LoRA to the PubmedQA Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0876ccef-8057-4bc3-ac8d-12dfcdf874ff",
   "metadata": {},
   "source": [
    "In this notebook you revisit the PubMedQA question answering task for GPT8B, but this time fine-tuning with LoRA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6175a-8738-4410-91d4-9833d5c8acbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d748140-6d92-4162-b783-05dbb3cbf6ec",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc7eec0-b1c2-424c-8eeb-edcafc981925",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you:\n",
    "- Will be able to perform LoRA fine-tuning.\n",
    "- Evaluate the performance of a LoRA fine-tuned 8B parameter model on the PubMedQA question answering task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33466089-960f-4355-b661-62161b8c5108",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9facce48-eabe-4e8d-a574-571fecfd858c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd69037-5e1b-48be-baf5-69505f45e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from llm_utils.nemo_service_models import NemoServiceBaseModel\n",
    "from llm_utils.models import LoraModels\n",
    "from llm_utils.mocks import create_pubmedqa_lora_customization as create_customization\n",
    "from llm_utils.pubmedqa import strip_response\n",
    "from llm_utils.helpers import plot_experiment_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dff6c4e-6d8f-4625-b19f-874dda0f0372",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675681e8-f9e1-4128-8b81-b0249f1f4356",
   "metadata": {},
   "source": [
    "## List Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a7026-1434-4588-924e-84e71170b92d",
   "metadata": {},
   "source": [
    "Here we've gathered the models available for LoRA fine-tuning provided by NeMo Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf7cfe-331a-4baa-9168-637bd9c9f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoraModels.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fddb39-5124-418e-8705-337d17a790c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b2df3-edbd-4541-9806-64da222bd6b8",
   "metadata": {},
   "source": [
    "## LoRA With NeMo Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd609da-33e6-4070-ba77-f5a4033d4169",
   "metadata": {},
   "source": [
    "If you know how to do p-tuning on the NeMo Service then you can do LoRA. The workflow, including the way data is formatted, is near identical. The only differences in the process between the two are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba821a38-9bba-46a9-9b52-932a624c92f1",
   "metadata": {},
   "source": [
    "1. We need to use a base model that support LoRA rather than p-tuning. `LoraModels` (listed above) contains these 2 models for your convenience.\n",
    "2. At customization launch time you no longer select for number of virtual tokens, which doesn't make sense in the context of LoRA.\n",
    "3. At customization launch time you need to select an **adapter dimension**. This is the value `r` in the image below: the rank of the **low-rank matrices**. A typical and good starting point for this value is 32. When using the `create_customization` method the parameter to set this value is `adapter_dim`. `adapter_dim` can be one of `{8, 12, 16, 32, 64}`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f67f859-5a61-4ae4-b638-1aa19d4ed833",
   "metadata": {},
   "source": [
    "![LoRA](images/lora_medium.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32bbe6-3f8f-4512-bc4f-f414698b9432",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84071be8-9a26-41e1-8236-efb30c2ff5f2",
   "metadata": {},
   "source": [
    "## Exercise Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9644c-1af4-4523-a5ab-239413021d9e",
   "metadata": {},
   "source": [
    "With that in mind, here is the command we used to run p-tuning using the PubMedQA dataset with the GPT8B model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e40f5e4-0c9c-4ed0-b56c-b2b61f9eebe3",
   "metadata": {},
   "source": [
    "```python\n",
    "conn.create_customization(\n",
    "    model=PtuneableModels.gpt8b.value,\n",
    "    name='pubmedqa-8b-token-50-batch-8-epochs-3',\n",
    "    description=\"P-tuning for custom pubmedqa model.\",\n",
    "    batch_size=8,\n",
    "    num_virtual_tokens=50,\n",
    "    training_dataset_file_id='cb1aab08-e396-41a8-9334-571c6672033d',\n",
    "    validation_dataset_file_id='42d75e3a-7aa9-46fa-b1c0-63d7a66f7a8f',\n",
    "    epochs=3\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67446d52-52ba-4743-882f-1689cdf04fe7",
   "metadata": {},
   "source": [
    "Your task is to launch a LoRA customization job for the same PubMedQA data using an appropriate GPT8B model. Instead of establishing an actual connection to NeMo Service with `conn.create_customization`, you will use our mock `create_customization` function imported above. If you don't pass in the correct arguments, the function will tell you. When you do successfully provide the correct arguments for the LoRA customization, the function will provide you with a customization ID for a LoRA customization we have already completed, that you will us later in this notebook.\n",
    "\n",
    "If you get stuck, feel free to check out the solution below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1cb4dc-0dc1-4126-b9b4-b3c987904e19",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a834f-0393-4338-b456-5fe90b57cbea",
   "metadata": {},
   "source": [
    "Correctly launch a (mock) LoRA customization using `create_customization` immediately below. On success, when you ascertain the customization ID, set the `customization_id` variable below to it for use later in the notebook.\n",
    "\n",
    "If you get stuck, feel free to check out the *Solution* below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3fc521-1bc5-4c69-a356-cb7774853683",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_customization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813c71b-9b1a-43dd-92ef-40b1103b9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "customization_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42764c2-ea59-47d7-b52f-2af77b2b89bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9a713-6b6e-4a24-8d62-a46fb6097271",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_customization(model='gpt-8b-000-lora',\n",
    "                     training_dataset_file_id='cb1aab08-e396-41a8-9334-571c6672033d',\n",
    "                     validation_dataset_file_id='42d75e3a-7aa9-46fa-b1c0-63d7a66f7a8f',\n",
    "                     adapter_dim=32,\n",
    "                     epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595ff0d0-e6a6-4d65-8c77-44c74550f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "customization_id = 'cab8b23d-b49d-4e35-bfad-3abc572d8f09'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478cc889-6703-41c6-bf2c-b72a3fb79a8f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c25f6d-a021-4b98-afb5-ec8fe2c53dc0",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4de38c-fccf-49d6-b1c4-77ea6d959cd5",
   "metadata": {},
   "source": [
    "Now that you have `customization_id`, set, let's proceed to load the test data and then evaluating the LoRA customization on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604cc5c-5464-4b11-9199-8dd6b62abbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_and_answers = json.load(open('data/pubmedqa_panda_test.json','r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b1285-09ad-49ce-afeb-feea90436e7f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d25f1-7556-49e4-8ec0-890f903b6060",
   "metadata": {},
   "source": [
    "## LoRA Customization Model Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34800e16-0c52-4680-8997-59c9dd71ccdc",
   "metadata": {},
   "source": [
    "Run the cell below to instantiate an instance of the LoRA fine-tuned GPT8B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e89190-a288-4ab3-82cc-131e0be03e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NemoServiceBaseModel(model=LoraModels.gpt8b.value, customization_id=customization_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce1969-b260-413d-a9ae-94a41ae0f66e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749691ae-d596-4629-a19b-c06745a5faf6",
   "metadata": {},
   "source": [
    "## Try Zero-shot Prompts With LoRA Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770f1b9-e024-4a43-8fe9-90ee69b38421",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt, answer in prompts_and_answers[::45]:\n",
    "    response = model.generate(prompt, tokens_to_generate=1, return_type='text').strip()\n",
    "    print(f'Response from model: {response}')\n",
    "    print(f'Actual answer: {answer}')\n",
    "    correct = response == answer\n",
    "    print(f'Response from model correct: {correct}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c8e58f-c919-4bd0-a083-bdd78d8472be",
   "metadata": {},
   "source": [
    "So far the LoRA fine-tuned GPT8B model appears to be performing quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c480f9de-9697-47f6-a8c1-abdb2b9c43fd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8859e38a-23d0-4836-b29f-de21712d3c75",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a510e-76e8-42ef-884e-68c3f20ce67d",
   "metadata": {},
   "source": [
    "Let's run a sanity test on evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba214d1c-8325-44cc-8ef9-e8e16430a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(prompts_and_answers[:5],\n",
    "                get_clean_prediction=strip_response,\n",
    "                tokens_to_generate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a1238-180e-4316-bbed-3944a4b5b2a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568e8b8-bd29-4c30-b365-ae3dac0e899b",
   "metadata": {},
   "source": [
    "## Zero-shot Prompting With P-tuned Model on Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58305534-a283-4dd6-a87f-e71dd156c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(prompts_and_answers,\n",
    "            get_clean_prediction=strip_response,\n",
    "            write_results_to_csv=True,\n",
    "            experiment_name='LoRA',\n",
    "            csv_file_name='experiment_results/pubmed_experiment_results.csv',\n",
    "            model_description='gpt-8b-000',\n",
    "            tokens_to_generate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1557d-b102-41fa-a320-1d75da709947",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment_results('experiment_results/pubmed_experiment_results.csv')\n",
    "# plot_experiment_results('experiment_results/solutions/lora_pubmed_experiment_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46eb62a-2093-4518-8b22-520e21a97962",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d7e3f-c7be-4704-ba9a-522bbef97315",
   "metadata": {},
   "source": [
    "The GPT8B LoRA fine-tuned model improved drastically! 8B's accuracy is now within 10% of the much larger 20B and 43B models.\n",
    "\n",
    "When we consider the advantages of using a smaller model, we may find it very worthwhile to give up 10% accuracy. The 8B model is faster, and being smaller is likely much less expensive to maintain, especially over time, due to its reduced GPU memory requirements.\n",
    "\n",
    "In addition to adding new functionality to models, this is one of the key value propositions for PEFT: moving functionality into smaller, faster, less expensive models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
