{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e2b3ed2-e1ce-42a4-9921-d44db6e10746",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed5df69-b0bf-4117-9fe9-9ccf50bcd692",
   "metadata": {},
   "source": [
    "# P-tune on PubMedQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0876ccef-8057-4bc3-ac8d-12dfcdf874ff",
   "metadata": {},
   "source": [
    "In this notebook we p-tune 3 NeMo GPT models for the PubMedQA question answering task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dcc5e9-e910-430a-a849-a42f2103c83b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db9ab1-3d78-4cd4-927a-2f8242fe9587",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2540cfb3-3423-4d66-86f7-dfa8c24de0f2",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will be able to:\n",
    "- Know how to create a p-tuning customization using NeMo Service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5eae7-d1e1-4d4b-acb2-63bbf1a9f323",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84da8f-480b-4765-8f49-3fb559c7a1d1",
   "metadata": {},
   "source": [
    "## Mocking the NeMo Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2baea-7f8d-457d-a1d1-ee6dbfc8d2b8",
   "metadata": {},
   "source": [
    "As mentioned in the previous notebook there are 2 places in this workshop where we will you will be interacting with mocks of the NeMo Service. The first was for file management, and the second is for running customization jobs like p-tuning and later, LoRA. We will still be confirming that you launch the customizations correctly.\n",
    "\n",
    "By mocking customization creation we can provide you with immediate access to customizations we have already created using the exact same process described in the workshop (exact same model, exact same data, exact same configurations) without you needing to wait for the customization jobs to complete which depending on the customization job in question is roughly between 5 and 30 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1894ca19-199d-4a74-8709-e7a2a4d64420",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf05907-4ef6-4494-b4a9-bfb1d4fc40fc",
   "metadata": {},
   "source": [
    "## Set IDs for Training and Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f679666d-f370-479e-948c-3518defee801",
   "metadata": {},
   "source": [
    "In the previous notebook you mock uploaded training and validation data and in the response from `upload` you received unique identifiers for the files. Typically you would capture those IDs to supply to your customization job, but in our case we will simply provide you with IDs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454b19e-e409-441e-ad39-89f3a9ead157",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_file_id = '6db1cb59-de77-426c-afb7-14220c0fee73' # ID obtained from file upload to NeMo Service in previous step\n",
    "validate_dataset_file_id = '4c5b9022-95d2-40a2-95d5-75115f6e7efb' # ID obtained from file upload to NeMo Service in previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd1400-09d6-4395-aaa0-b87d4b667199",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e85a1ae-93f8-4968-9cb2-87f7029139e7",
   "metadata": {},
   "source": [
    "## Create Customization (P-tuned Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d14b4-7dcc-409d-b7c3-1f3c1e5b707d",
   "metadata": {},
   "source": [
    "With the data uploaded and well-formatted, p-tuning with NeMo Service is incredibly simple, all we have to do is use the `conn.create_customization` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d9338-52ee-4712-96e1-635a8a912950",
   "metadata": {},
   "source": [
    "### Create Customization Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1196e9-117a-43a0-805c-43acf24c40c0",
   "metadata": {},
   "source": [
    "Let's look at the docstring for `conn.create_customization` to better understand how we should use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d4af6-3225-47d1-bfaf-70e0cff27a70",
   "metadata": {},
   "source": [
    "```python\n",
    "Help on method create_customization in module nemollm.api:\n",
    "\n",
    "create_customization method of nemollm.api.NemoLLM instance\n",
    "    - model: str\n",
    "    - training_dataset_file_id: str\n",
    "    - name: str\n",
    "    - description: Optional[str] = None\n",
    "    - training_type: Optional[str] = None\n",
    "    - shared_with: Optional[List[str]] = None\n",
    "    - validation_dataset_file_id: Optional[str] = None\n",
    "    - batch_size: Optional[int] = None\n",
    "    - epochs: Optional[int] = None\n",
    "    - learning_rate: Optional[float] = None\n",
    "    - num_virtual_tokens: Optional[int] = None\n",
    "    - adapter_dim: Optional[int] = None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b000847-326b-4549-955d-52011ec7113a",
   "metadata": {},
   "source": [
    "As you can see there are a number of parameters we can pass in.\n",
    "\n",
    "Required are the name of the model you wish to p-tune, the human-readable name of the customized model, and the ID of the training dataset. If you do not supply a validation dataset file, NeMo Service will take care to split off 10% of your training data to use for validation.\n",
    "\n",
    "In addition to these required fields, you can also override the training hyperparamter defaults. In the case of p-tuning we should consider the following hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed18da68-b8fb-4f1c-a7a0-b71a4a718438",
   "metadata": {},
   "source": [
    "### Batch Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ec579-984b-444c-8e7b-2501655ee599",
   "metadata": {},
   "source": [
    "The default value is 8. A value of 16 is often recommended as a good place to start experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44da21f-e22b-45be-a87f-b6cdfd36eba3",
   "metadata": {},
   "source": [
    "### Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1153f6-81b4-466e-8d7b-f02b848234c0",
   "metadata": {},
   "source": [
    "The default value is 50. Depending on the job a single epoch can do the trick, but typically 3 to 10 epochs is better. NeMo Service will end training early if after 10 epochs the validation error has not improved, so, unless you're in a tremendous rush, you can just set this to 50 and see when the job completes early.\n",
    "\n",
    "Depending on NeMo Services's load, your p-tuning job may begin immediately or may be queued up for up to 5 minutes or so. It depends on your dataset size, the length of your generation, the batch size, and the size of your model (smaller is faster), but typically you can expect ~5-10 minutes per epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7b7df-749f-42e4-a460-03d32c3c83ff",
   "metadata": {},
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c57a6-f6ed-469c-81ab-79d5928dc9a0",
   "metadata": {},
   "source": [
    "Set to a good default of .0001, you can adjust this if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fd8854-0cc0-448a-aaec-41418e22b95d",
   "metadata": {},
   "source": [
    "### Number of Virtual Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81229a-3324-48df-984b-57d5d305ef43",
   "metadata": {},
   "source": [
    "Specific to p-tuning, this is where you configure how many virtual tokens to train. The default is 50, but for smaller models you might consider beginning your experiements with a smaller value like 10. Experimentation and observation of empirical results in the best way to obtain the optimal value, but we have found the default value of 50 to be an excellent value to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598afa73-362d-4172-b57c-0ce6d201b07f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8f5f8-9b8b-49a2-9151-e56978774f06",
   "metadata": {},
   "source": [
    "## Run P-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c8d8f-04d9-4fa3-a20b-b4762586d29a",
   "metadata": {},
   "source": [
    "We've already run the p-tuning jobs for this task, so you don't need to actually run the jobs yourself, but for your reference, the following cells show how we ran the jobs that resulted in the models we will be using in the next notebook. In each case we trained for 3 epochs with the default values for batch size (8), number of virutal tokens (50) and learning rate (.0001). We ran these jobs concurrently and on average each took 20 minutes to train over 3 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daabe5e-8641-44d5-bcf4-df773718414f",
   "metadata": {},
   "source": [
    "```python\n",
    "response_43b = conn.create_customization(\n",
    "    model=PtuneableModels.gpt43b.value,\n",
    "    name='pubmedqa-43b-token-50-batch-8-epochs-3',\n",
    "    description=\"P-tuning for custom pubmedqa model.\",\n",
    "    batch_size=8,\n",
    "    num_virtual_tokens=50,\n",
    "    training_dataset_file_id=training_dataset_file_id,   \n",
    "    validation_dataset_file_id=validate_dataset_file_id,   \n",
    "    epochs=3\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f6e43e-a62d-4ed2-ae1b-cf7e1caa83a4",
   "metadata": {},
   "source": [
    "```python\n",
    "response_20b = conn.create_customization(\n",
    "    model=PtuneableModels.gpt20b.value,\n",
    "    name='pubmedqa-20b-token-50-batch-8-epochs-3',\n",
    "    description=\"P-tuning for custom pubmedqa model.\",\n",
    "    batch_size=8,\n",
    "    num_virtual_tokens=50,\n",
    "    validation_dataset_file_id=validate_dataset_file_id,   \n",
    "    training_dataset_file_id=training_dataset_file_id,   \n",
    "    epochs=3\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33973b-a09f-45fe-9806-0e5fe9def211",
   "metadata": {},
   "source": [
    "```python\n",
    "response_8b = conn.create_customization(\n",
    "    model=PtuneableModels.gpt8b.value,\n",
    "    name='pubmedqa-8b-token-50-batch-8-epochs-3',\n",
    "    description=\"P-tuning for custom pubmedqa model.\",\n",
    "    batch_size=8,\n",
    "    num_virtual_tokens=50,\n",
    "    validation_dataset_file_id=validate_dataset_file_id,   \n",
    "    training_dataset_file_id=training_dataset_file_id,   \n",
    "    epochs=3\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
