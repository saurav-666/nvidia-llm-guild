{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9503e57e-ea41-4527-9ddd-9ee357d83e26",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dafaa2-378e-4dd3-939a-4af968cc7999",
   "metadata": {},
   "source": [
    "# Section 2: PEFT Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca750e16-b16e-4756-a9b2-ea1660ea4088",
   "metadata": {},
   "source": [
    "In this section you will learn to perform the parameter efficient fine-tuning techniques p-tuning and LoRA in the context of a challenging medical question answering task while performing quantitative performance analysis across multiple GPT models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244873d-360e-4ad1-a8a2-7eb7a79fa314",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd723bf-6069-4764-ac9c-71a9ed76339e",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f04cea-144b-481b-bd49-a9d2e822367c",
   "metadata": {},
   "source": [
    "1. **PubMedQA Data:** In this notebook you will explore the PubMedQA dataset which will serve as the basis for customization experiments in this section.\n",
    "1. **PubMedQA With Zero-Shot Prompts:** In this notebook you will obtain zero-shot baseline performances for several LLMs on the PubMedQA question answering task.\n",
    "1. **PubMedQA With Few-Shot Prompts:** In this notebook you continue establishing a baseline on PubMedQA before performing PEFT, but this time with few-shot prompting.\n",
    "1. **P-tuning Simplified:** In this notebook you will learn how the PEFT technique p-tuning works.\n",
    "1. **Data for P-tuning:** In this notebook you will prepare the PubMedQA data for use in p-tuning.\n",
    "1. **P-tune on PubMedQA:** In this notebook you will p-tune 3 NeMo GPT models for the PubMedQA question answering task.\n",
    "1. **Evaluate P-tuning:** In this notebook you will evaluate the performance of the 3 p-tuned GPT models on the PubMedQA question answering task.\n",
    "1. **LoRA Simplified:** In this notebook you will learn how the PEFT technique LoRA works.\n",
    "1. **LoRA for PubMedQA:** In this notebook you perform LoRA fine-tuning for the PubMedQA question answering task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8eef75-3473-4721-9386-9b66f62eb353",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
