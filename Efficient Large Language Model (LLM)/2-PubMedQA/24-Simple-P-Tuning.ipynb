{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1634e0-eb2d-413d-8cc4-d350052445d9",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6852dcf-c938-41f0-b138-68e11d366e2e",
   "metadata": {},
   "source": [
    "# P-tuning Simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1760a68e-ec5e-44dd-a8b8-c39b6fae449b",
   "metadata": {},
   "source": [
    "Before beginning PEFT for the PubMedQA task, beginning with the PEFT technique p-tuning, we will, in this notebook, cover the main concepts behind p-tuning and construct a simplified p-tuning mechanism to help develop your intuition about p-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef8871-0db1-4009-a96d-22f3a250256b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52007e7-c2c7-44e7-a917-c339654e2e67",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e9b7e-8a3c-4e0b-9bc0-afcd10487287",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will understand:\n",
    "- How the PEFT technique p-tuning works.\n",
    "- How a relatively small deep learning model can be trained to create embeddings that support specific LLM behavior.\n",
    "- Why p-tuning is considered an efficient fine-tuning method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60957188-fdf1-4b02-895e-d1b03c0bba57",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01d619-4a78-485b-b042-711c7441c6f9",
   "metadata": {},
   "source": [
    "## P-tuning Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f633f-2097-4658-a4a0-fcbde71b5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_utils.slides import load_p_tuning_slides\n",
    "load_p_tuning_slides()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a3edd2-7983-428e-aca4-7532b57440e8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eb5f3c-5e28-43ec-a509-940137029b1c",
   "metadata": {},
   "source": [
    "## P-tuning Simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ae37e8-0069-45ab-8507-f9cfbb8fdc9a",
   "metadata": {},
   "source": [
    "For the remainder of the notebook we will create a simplified p-tuning mechanism to assist your intuition about how p-tuning works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85e189-6273-49ff-9e76-9ee17e95f3b0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a69498-b23c-41ea-8d4d-17f718fad5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63366dcc-331a-40b8-a306-58791cb2f4ca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa63669-6fcc-4171-937c-25dd5accfc31",
   "metadata": {},
   "source": [
    "## P-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4583747-2925-41e9-80ef-f43906ff4f49",
   "metadata": {},
   "source": [
    "P-tuning is a PEFT technique whereby we train a relatively small multi-layer perceptron **(MLP)** neural network, called a **prompt encoder (PE)**, to create **virtual tokens** (also referred to as virtual prompts, soft prompts, and virtual embeddings) which can be added to LLM input to improve the likelihood that the LLM supplies the kind of generation we would like.\n",
    "\n",
    "Part of what makes p-tuning an \"efficient\" fine-tuning method is that the weights of the LLM we are working with are frozen during p-tuning, and only the prompt encoder (PE) weights, which typically consists of only a few million parameters, are trained.\n",
    "\n",
    "Thus, while it is common to say things like \"p-tune an LLM\" or \"use a p-tuned LLM\" in fact the LLM is not updated or trained at all during the p-tuning process, only the small PE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6382c5-4df2-4e26-9e4f-c5540d86a0a0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb64a6-86c0-4cca-aa5e-dea0bc900c42",
   "metadata": {},
   "source": [
    "## With vs. Without P-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a07940e-d365-42fa-acfe-8cbbb5dfd231",
   "metadata": {},
   "source": [
    "If we envision a typical prompt to response process with an LLM looking like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac026d8-d96f-48db-8bef-3115ae224b43",
   "metadata": {},
   "source": [
    "```python\n",
    "prompt -> (tokenizer) -> tokens -> (embedding_layer) -> embeddings -> (LLM) -> output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a6c2af-2ce9-4c6a-8e0b-53704b778e50",
   "metadata": {},
   "source": [
    "Then with p-tuning it would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162e215-e655-4ecc-a3a6-5fe842ce7ce5",
   "metadata": {},
   "source": [
    "```python\n",
    "prompt -> (tokenizer) -> tokens -> (embedding_layer) -> embeddings -> (MLP PE) -> embeddings+virtual_tokens -> (LLM) -> output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc10348-b833-447a-9598-44131661609b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f95a1d-a29c-4dcf-8b68-a081c11a5a56",
   "metadata": {},
   "source": [
    "## The Efficiency of P-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb97e55-da20-4fe5-996b-bda1fdf74e04",
   "metadata": {},
   "source": [
    "P-tuning can be performed with a relatively small amount of data, only hundreds to a few thousand samples, and depending on the task can result in performance as well as models that went through full supervised fine-tuning for the task.\n",
    "\n",
    "As an additional benefit, p-tuning is well suited to fine-tuning a single LLM for multiple tasks. Either we can perform a single p-tuning with data that represents multiple tasks we would like the LLM to perform on, or, we can undergo multiple rounds of p-tuning, which results in multiple task-specific prompt encoders. Then during inference, depending on the task we would like to perform, we can simply pass our prompt through the relevant prompt encoder on its way to the LLM, with the possibility of many such prompt encoders existing in front of the LLM for use in a variety of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f89661c-7cf4-4c91-adf4-cfa47fe94291",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d845f-c82d-4f8d-8b7d-d5592792a85c",
   "metadata": {},
   "source": [
    "## P-tuning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4e17c-2d7b-467c-aef3-70e290e10a3b",
   "metadata": {},
   "source": [
    "We'll look in more depth at the p-tuning process below, but in summary it's rather straight forward deep learning training process. During p-tuning we:\n",
    "1. Provide training data with prompt/desired-response pairs.\n",
    "2. Include (at first randomly generated) virtual embeddings supplied by the PE to the user-supplied prompt embeddings.\n",
    "3. Compare the LLM's output to our desired-respone label and calculate a loss.\n",
    "4. Back propogate through the LLM back to the PE and w/o updating the LLM weights, do update the PE weights\n",
    "5. Repeat until our training objectives are met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a43f51-3ae2-4530-a230-777b9e24ab31",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d744a-a4fb-4bd3-9ad1-d6e9c6414568",
   "metadata": {},
   "source": [
    "## Simulating P-tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fb32048-92d5-4eaa-9d9d-3f303bafa933",
   "metadata": {},
   "source": [
    "In order to improve your intuition about how p-tuning works, we will be simulating it in a simplified way in this notebook.\n",
    "\n",
    "In our simulation of p-tuning we will define the following components:\n",
    "- A small matrix of fixed weights to represent a simplified version of an LLM.\n",
    "- A set of **virtual tokens** represented as embeddings.\n",
    "- A **prompt encoder** (a small matrix or vector) that will be updated to produce better **virtual tokens**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b974492-2c44-4f53-b683-7e079f809cc9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1cb731-f515-4d34-9c63-326438550d3f",
   "metadata": {},
   "source": [
    "## Embedding Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150458fe-c084-4522-a105-3e3a6ac5b213",
   "metadata": {},
   "source": [
    "When a Large Language Model (LLM) converts tokens into embeddings, the size of these embeddings is always a fixed number, determined by the architecture of the LLM. In the spirit of this notebook (taking a *simplified* look at p-tuning) we set the embedding dimension here to a small value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af9560-917d-4098-b6f5-904dfc5df389",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4dd1cb-4929-4d5e-afb7-f397ab19cab0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791ceed-1091-4b41-963f-6e40455c8561",
   "metadata": {},
   "source": [
    "## Number of Virtual Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d1c8df-d2c3-45c2-8a81-103c78ad9303",
   "metadata": {},
   "source": [
    "During p-tuning, we specify the number of virtual tokens to train, typically ranging from 10 to 50. In the spirit of this notebook we choose here a small value 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038818e-3593-4ce6-93a9-1cba9f9c0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_virtual_tokens = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d842a-c8c5-4d26-8dca-c1c363928796",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c4afb-0009-4529-a5fc-4d4187c7a303",
   "metadata": {},
   "source": [
    "## The LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f855682-3b50-49d0-98df-615ed584de41",
   "metadata": {},
   "source": [
    "As you are aware LLMs commonly have billions of parameters consisting of many weight matrices. For this example notebook we define the LLM to be a single, small, weight matrix. Because this single matrix represents the entire LLM, it will both receive the embedding inputs and produce the LLM's output, thus we shape it as `embedding_dim` by `llm_output_dim`.\n",
    "\n",
    "Worth mentioning that like in legitimate p-tuning, the `llm_weights` will be fixed throughout the process of p-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1638105-0846-4d2e-93c9-236cf6337f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_output_dim = 3 \n",
    "\n",
    "llm_weights = np.random.randn(embedding_dim, llm_output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4934fe16-3989-4b21-a96a-74052a118b95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26109c4-7a38-45f8-a5c5-ffd8f8816990",
   "metadata": {},
   "source": [
    "## Initialize the Prompt Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882488c-586f-488e-8908-2828a0400046",
   "metadata": {},
   "source": [
    "The prompt encoder is typically a several million paramter MLP (multi-layer perceptron) neural network. Here we initialize it as a small matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783e931-fa3b-444f-aa5e-482337ab11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_encoder = np.random.randn(num_virtual_tokens, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0cfed-f7db-4695-b11f-31c6941dd279",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b10364-d9f4-4d7a-9994-800865149689",
   "metadata": {},
   "source": [
    "## Initialize the Virtual Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ecc17e-f301-4ac9-8bad-cb9fbd5024a7",
   "metadata": {},
   "source": [
    "Each virtual token will be the same rank as the model's embedding dimension. Before p-tuning, virtual tokens are initialized to random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8026c-7d90-4350-bf74-a95eb2cb4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_tokens = np.random.randn(num_virtual_tokens, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e33d2f-00f0-411c-ba26-a71aba9ae1ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b514235-958c-4ea7-82c4-677aa6bcb20f",
   "metadata": {},
   "source": [
    "## Simulate Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccaf320-89d8-40b4-bbf1-6f2b9df29963",
   "metadata": {},
   "source": [
    "Here we simulate the hard prompt input to the LLM as a 1 x embedding dimension vector. Real inputs will be matrices of size number of embeddings x embedding dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa0411-4c34-477b-af63-c0e8deb1240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = np.random.randn(1, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a9c53-caf8-4135-8c18-cbef96add03c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187694bb-7533-423b-9f76-70e2c492ee9d",
   "metadata": {},
   "source": [
    "## Simulating a Forward Pass Through the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14485a37-293b-40a4-8b35-d8bc7df3db20",
   "metadata": {},
   "source": [
    "During p-tuning, the prompt encoder updates the virtual tokens, which are then fed into the LLM (represented here by the fixed weight matrix) along with the hard input tokens. We'll simulate a simple forward pass and loss calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f2c18-a084-4cdb-8ee1-f10bec6ce40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(input_vector, virtual_tokens, llm_weights):\n",
    "    # Concatenate virtual tokens with the input vector\n",
    "    combined_input = np.concatenate((virtual_tokens, input_vector), axis=0)\n",
    "    \n",
    "    # Pass through the LLM\n",
    "    llm_output = np.dot(combined_input, llm_weights)\n",
    "    return llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cd3c2-4545-4ab8-a11a-1d1bacd924a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass with initial virtual tokens\n",
    "initial_output = forward_pass(input_vector, virtual_tokens, llm_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd5e6a-f59d-4233-9a4f-4e22cfed6929",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e3e778-0782-449f-a7bf-1b1bfe9f057e",
   "metadata": {},
   "source": [
    "## Calculate the Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40699e1-3bab-41a9-9900-9d3878a4f219",
   "metadata": {},
   "source": [
    "Here we assume a simple loss function (mean squared error) against a target output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bf4dd-4867-4e83-9453-39b9073da4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.random.randn(1, llm_output_dim)  # Target output\n",
    "loss = np.mean((initial_output - target)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c59d6-e113-4218-8fa6-49207e2093f3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beaaad4-fde9-4950-8163-a9aea84b3a99",
   "metadata": {},
   "source": [
    "## Calculate the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69dbe7c-da95-49f8-a85c-7fcc734cc08b",
   "metadata": {},
   "source": [
    "In p-tuning, the gradient for the Prompt Encoder is calculated by backpropagating the loss through the entire LLM to determine how changes in the prompt encoder's parameters affect the final output, even though only the parameters of the prompt encoder are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcae8e5-f2aa-4d7a-9512-4d4ecb530bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy gradient: actual gradient for the Prompt Encoder is calculated by backpropagating the loss through the entire LLM\n",
    "prompt_encoder_gradient = np.random.randn(num_virtual_tokens, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b72f9-ef66-4e14-92f1-9758b029befe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba5cfba-31e8-47bf-9c06-9307ad49e01d",
   "metadata": {},
   "source": [
    "## Update Prompt Encoder Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904d2ef-02ff-47f0-887c-fc12c987a121",
   "metadata": {},
   "source": [
    "While the LLM weights remain frozen, we of course update the weights of the prompt encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cbb091-46b9-4b15-847e-76eb8f622d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "prompt_encoder -= learning_rate * prompt_encoder_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf905ef0-0dfd-4142-964a-845d78c94ae3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023fdc44-4942-4417-9afc-2be180026af0",
   "metadata": {},
   "source": [
    "## Update Virtual Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c1564-10bc-4ea2-b90d-d14766ff70d9",
   "metadata": {},
   "source": [
    "After the prompt encoder has been updated, it performs a transformation on the original virtual tokens to produce updated virtual tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69505376-c354-4101-9dde-ac0838ededa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the transformation of virtual tokens using matrix multiplication\n",
    "# with the updated prompt_encoder\n",
    "original_virtual_tokens = virtual_tokens\n",
    "virtual_tokens = original_virtual_tokens * prompt_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af07faf-6c4d-4cab-b8d6-ef3803863b63",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19a577-0ece-4ed1-b108-ff81c8c8361a",
   "metadata": {},
   "source": [
    "## Repeat Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f9b84-76ef-4f6a-80f5-29ff76a18987",
   "metadata": {},
   "source": [
    "The updated virtual tokens are now used in the next forward pass as prompt encoder training continues until some specified training objective (number of epochs, validation loss, etc.) has been reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e535af7-aa4d-4b10-ac86-ab4eb0cbe381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass with updated virtual tokens\n",
    "updated_output = forward_pass(input_vector, virtual_tokens, llm_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf1c5d-d346-4e0f-9c1f-77cfa0bbc4ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18afc518-2e9e-4a4b-be48-04f4fc6b9890",
   "metadata": {},
   "source": [
    "## Post-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21233ec3-660e-4981-8abf-cf7d5ae09bee",
   "metadata": {},
   "source": [
    "The final virtual tokens that were the result of the p-tuning process are now used in during post-training inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53980377-07f7-46c7-9312-b12a60d000f6",
   "metadata": {},
   "source": [
    "```python\n",
    "prompt -> (tokenizer) -> tokens -> (embedding_layer) -> embeddings -> (MLP PE) -> embeddings+virtual_tokens -> (LLM) -> output\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
