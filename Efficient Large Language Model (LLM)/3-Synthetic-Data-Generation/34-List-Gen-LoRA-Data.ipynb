{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b936c83-bc8f-4c5d-9fd4-377428ba3f31",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6ee00-e5b0-4973-b6f1-0e3c2f0db6c4",
   "metadata": {},
   "source": [
    "# List Generation - LoRA Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84298a5d-b114-4931-9a13-4e1db488ce94",
   "metadata": {},
   "source": [
    "In this notebook you resume your work on synthetic data generation (SDG).\n",
    "\n",
    "Previously you used a GPT43B-based list generation function to generate many seed topics. In this notebook you will use the current 43B-based function along with the seed topics to generate synthetic data, prompts and labels, that you will use in a later notebook to fine-tune a GPT8B model for list generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c341ad0-8be4-483e-be39-aa2bf678b4a2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0452ac1-520e-40f1-86a6-b6d7b55c5651",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de794f-ba9c-4e26-a62c-975de9cf591d",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you:\n",
    "- Will generate synthetic data for fine-tuning an 8B model for list generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212edcea-e124-46e1-be4b-e4e1e0ed7154",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97dd1eb-61f1-4375-8e53-964f1f2c9cca",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2b417-98b7-4ddc-8587-6fe8586cfe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from llm_utils.llm_functions import generate_list_43B as generate_list\n",
    "from llm_utils.prompt_templates import gen_list_template_zero_shot as gen_list_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa26ab3-3316-4386-932c-dbe1e86b65c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a1af6-c7fc-4b50-9396-ab481b6fc6d9",
   "metadata": {},
   "source": [
    "## Review List Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcffbb8-ab61-4595-9d1e-c290de2d2d8a",
   "metadata": {},
   "source": [
    "In a previous section, you worked to create a `generate_list` function that relied on a prompt-engineered GPT43B model to generate lists of seed topics. We have provided our implementation of this function for you here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1629ebf2-76f9-413e-aceb-8e54b9be4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways = generate_list(5, 'ways to feel great every day.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99249d80-ee25-41c8-bef0-2c3d20c6ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1fabfe-f8ac-4466-a758-afadd6e44916",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50091e78-d4cf-49d3-b5e2-002e3c5a20bd",
   "metadata": {},
   "source": [
    "## List Generation Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c5f31-f201-49e0-8462-5578afc42e15",
   "metadata": {},
   "source": [
    "Also in the previous notebook you synthetically generated 100 unique seed topics. If you recall, these things were intended to be used in in the very prompts we send to `generate_list`, namely:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c69fb-0691-4c24-96c7-59124d21bee8",
   "metadata": {},
   "source": [
    "```python\n",
    "f'Make a python list of {len} {topic}.'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b44ede7-84dd-4353-9257-0e7af57baf7b",
   "metadata": {},
   "source": [
    "Since you will be utilizing this prompt template extensively in conjunction with loops, we've provided the helper `gen_list_template` function to accept arguments `len` and `topic` and return the prompt using the specified values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3f91f-da48-4fea-b578-08458627d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_list_template(5, 'good ideas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142f313-b8c0-46f4-9b7c-42e52f6cd594",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a467bf-9080-4e5b-bf97-49d88840575c",
   "metadata": {},
   "source": [
    "## Review Seed Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfdb514-66ba-478f-86d5-372811a8fd1b",
   "metadata": {},
   "source": [
    "Using the same process you did earlier, but with extra time on our hands, we generated a list of 254 seed topics that we have provided for you to use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7a4fb-c39b-4ad4-8a78-ba58a19d4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/254_seed_topics.json', 'r') as f:\n",
    "    seed_topics = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5e0af-423b-4e52-8160-ed3b7448d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seed_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e56eb-ea96-4386-9e1a-359a3b3b7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topics[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317805c-60cc-418a-a586-fcad80c8feb4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332098da-e145-4625-a8ba-ef2463a2a4a1",
   "metadata": {},
   "source": [
    "## Generate List Generation Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73d2920-e8c2-4ed9-b1de-da00a6cbe71d",
   "metadata": {},
   "source": [
    "These seed topics can be passed into `gen_list_template` to generate appropriate prompts for list generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5632dd1-fa14-48a9-b6b5-efcc1e3ef373",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seed_topic in enumerate(seed_topics[:5]):\n",
    "    print(gen_list_template(i+2, seed_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c29e9-c0f1-4f21-9b80-8284a4a27326",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16500b8e-f7be-4253-899e-63f956218023",
   "metadata": {},
   "source": [
    "## Exercise: Generate Data for Fine-Tuning List Generation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fac6e1-d3a3-419b-875c-80dd3699685b",
   "metadata": {},
   "source": [
    "![List Gen Data](images/list_gen_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00609fcd-07ef-4259-91f1-77c314ffd398",
   "metadata": {},
   "source": [
    "In this exercise you will aim to populate `prompts_with_labels` with 100 prompt/label pairs intended for use in fine-tuning a GPT8B model to perform list generation. This is inline with the virtuous cycle we have discussed where we can prompt engineer a larger model to perform a task and then use this larger model's responses to create data for fine-tuning a smaller model to perform the same task.\n",
    "\n",
    "Your `prompts_with_labels` should be a list of 2-tuples in the format `({prompt}, {label})` where `prompt` is an appropriately formatted prompt for list generation, and `label` is a well-formed list without duplicates of the correct size.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a429fe-70fa-4d2e-89c3-925398bbed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompts_with_labels = []\n",
    "topics = ['colors', 'magicians']\n",
    "for i, topic in enumerate(topics):\n",
    "    n = i+2 # We don't want 0, or 1 things\n",
    "    prompt = gen_list_template(n, topic)\n",
    "    label = generate_list(n, prompt)\n",
    "    prompt_with_label = (prompt, label)\n",
    "    example_prompts_with_labels.append(prompt_with_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84bd59-8a44-40f6-b741-775923da0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompts_with_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be41bd6-3b26-4a4c-a976-80088969394e",
   "metadata": {},
   "source": [
    "### Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e85b1-a4b7-41c8-8abf-9e7d57395273",
   "metadata": {},
   "source": [
    "Before you begin, it might be worth keeping the following in mind:\n",
    "- Since this data is intended for training, you want a diversity of data. Be sure to create lists of varying length, and use as many different `seed_topics` in your prompts as you can.\n",
    "- `generate_list` performs best with `n` < 7.\n",
    "- `random.randint(begin, end)` will give you an integer between the range of `begin` and `end`.\n",
    "- `generate_list` will return an empty list if it fails. Be sure to handle this when populating `prompt_with_labels`.\n",
    "- In spite of your efforts, there's always a chance `prompt_with_labels` ends up with duplicate items. Consider taking care to address this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883a7a3-43dd-442b-b87b-c73cfc92bd2e",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7067bf26-d224-4f2c-bf06-c4085295c234",
   "metadata": {},
   "source": [
    "Here is the actual `prompts_with_labels` you should populate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51829d-8401-42ed-b0a5-d840ed25cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_with_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f54b6-05a0-4246-8828-423a22b88375",
   "metadata": {},
   "source": [
    "If you get stuck, feel free to check out our solution below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f80a8-716f-45b0-b5c2-bc13306b6133",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45332062-ab7a-4203-b254-a69339f95a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1) # We set a seed just for reproducibility\n",
    "solution_prompts_with_labels = []\n",
    "# Set to 10 for the sake of time.\n",
    "# In reality we would set to ~120 to overshoot our target of 100 in case of duplicates.\n",
    "for seed_topic in tqdm(seed_topics[:10]):\n",
    "    n = random.randint(2, 8)\n",
    "    prompt = gen_list_template(n, seed_topic)\n",
    "    label = generate_list(n, prompt)\n",
    "    if len(label) == n: # Make sure label is a well-formed list. Empty lists will not enter this `if` statement.\n",
    "        random.shuffle(label) # Not required, but will help avoid some duplication and possibly diversify data.\n",
    "        solution_prompts_with_labels.append((prompt, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040750b-a68b-4730-bf01-41773b4eff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, l in solution_prompts_with_labels[:10]:\n",
    "    print(f'Prompt: {p}')\n",
    "    print(f'List: {l}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
