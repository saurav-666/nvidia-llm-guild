{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75760310-6555-4c54-aa98-9fdcf460d958",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c1200-ef1e-48fe-a4e4-f6a61971b461",
   "metadata": {
    "tags": []
   },
   "source": [
    "# List Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056eb461-b9c7-401f-b2e8-da50e8908c48",
   "metadata": {},
   "source": [
    "In this notebook we introduce a Python list generator LLM function that leverages a prompt-engineered LLM and can return Python lists of a given size containing items that fit a given description.\n",
    "\n",
    "In later sections you will use the list generation function extensively, largely in service of creating synthetic data to use for fine-tuning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113bf23-643c-40bc-958b-eaa5fbe891bf",
   "metadata": {},
   "source": [
    "![List Gen 43B](images/list_gen_43b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b3e0a-7296-41fb-98cb-3bb688bc9971",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684bef4b-cacf-4580-9294-eb97ee671a97",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9629816-ebde-4b26-8ad9-e786c1a5cacd",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will be able to:\n",
    "- Build an LLM-powered Python list generator for later use in synthetic data generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0645ae-db96-491c-97dd-329caf6242dd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12ce63-7179-405b-86cf-03e49f51f354",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807cfa5-a29a-4e8b-ac92-063655341429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "from llm_utils.models import LoraModels\n",
    "from llm_utils.nemo_service_models import NemoServiceBaseModel\n",
    "from llm_utils.prompt_creators import create_nemo_prompt_with_examples\n",
    "from llm_utils.llm_functions import make_llm_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afacb8-7f4d-4c83-adb8-248bb5241107",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70a674-0b2c-427e-9b4c-2df7b1d3ae0b",
   "metadata": {},
   "source": [
    "## List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc20760-ac15-403a-ae32-7986f4bedacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoraModels.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ccf3cf-16ca-4ed1-8a47-6af206babd06",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcffdf2-6bd8-4196-beb9-85a02ff4179b",
   "metadata": {},
   "source": [
    "## List Generator LLM Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e4849-4f0f-40d3-81a5-c7fc5f8cd258",
   "metadata": {},
   "source": [
    "Our present goal is to create an LLM function called `generate_list` that will expect 2 arguments, `n` and `topic` and which will generate a literal (not string) Python list of length `n` containings items for the given `topic`.\n",
    "\n",
    "As you recall, the way we are constructing LLM functions requires 3 components: a model instance, a prompt template, and optionally, a postprocessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf460c-c5f4-429d-9ba8-dea30f2c7f0e",
   "metadata": {},
   "source": [
    "### Model Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b21e8-0bc6-42f5-afa6-ddda4472abcb",
   "metadata": {},
   "source": [
    "We begin by instantiating a model instance. Here we will use GPT43B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d55910-732f-4162-938c-7369d1e13caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NemoServiceBaseModel(LoraModels.gpt43b.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6d760-0ec7-42dd-a3e0-f09dd54e0c5a",
   "metadata": {},
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51fe8b4-d6f0-4c7b-adfc-958e111aebb4",
   "metadata": {},
   "source": [
    "Through prompt engineering we arrived at `gen_list_template` below.\n",
    "\n",
    "It contains a main prompt `'Make a python list of {n} {topic}'`, and includes 3 example shots for how the model ought to respond. We are using a helper function `create_nemo_prompt_with_example` (introduced in the PubMedQA section of the workshop) to help us construct example shots formatted appropriately to the instruction fine-tuned NeMo GPT43B model we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e0355-6785-4e02-9fda-5259e69066b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_list_template(n, topic):\n",
    "    conversation_examples = [\n",
    "        ('Make a python list of 2 animals.', '[\"dog\", \"spotted owl\"]'),\n",
    "        ('Make a python list of 3 books.', '[\"The Three Body Problem\", \"Dandelion Wine\", \"Deep Learning and the Game of Go\"]'),\n",
    "        ('Make a python list of 6 times of day.', '[\"morning\", \"evening\", \"night\", \"midday\", \"midnight\", \"dawn\"]')\n",
    "    ]\n",
    "    main_prompt = f'Make a python list of {n} {topic}.'\n",
    "    return create_nemo_prompt_with_examples(main_prompt, conversation_examples=conversation_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39df24c-5780-4045-bcef-b6dbff114806",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3006d47-0fe2-487e-91cf-a9c70739a2bc",
   "metadata": {},
   "source": [
    "We want our function to return a literal Python list, and we take care to ensure that in the following postprocessing function `postprocess_list`, which does several important things:\n",
    "\n",
    "- It uses Python's `ast.literal_eval` to try to convert the model's string response to a literal list.\n",
    "- In cases where the model response is not a well-formed list, it returns an empty Python list.\n",
    "- In situations where our model response may have included duplicate items, we deduplicate the list by casting it to a set and then back to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5bcbd-55c1-4dba-a276-d58e6acf69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_list(list_str):\n",
    "    try:\n",
    "        # If the model response is a well-formed list, this will convert the string into a Python list\n",
    "        literal_list = ast.literal_eval(list_str)\n",
    "    except:\n",
    "        # In cases where the model response is not a well-formed list we return an empty list\n",
    "        literal_list = []\n",
    "\n",
    "    # We can deduplicate the list by casting it to a set and then back to a list\n",
    "    deduplicated_list = list(set(literal_list))\n",
    "    return deduplicated_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3112ad01-7553-4cc0-b10b-653981d972cd",
   "metadata": {},
   "source": [
    "### Create the LLM Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bfa241-effc-4c4f-9016-f2ca55cc69d5",
   "metadata": {},
   "source": [
    "Using the model instance, our prompt template and our postprocessor we create the `generate_list` LLM function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45969151-96fa-4e6a-8b51-29758d91dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_list = make_llm_function(model, gen_list_template, postprocess_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfeb929-53bf-4fb0-b287-630e3fe22e69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe163cc9-1a0a-4745-b587-b5e8ed467834",
   "metadata": {},
   "source": [
    "## Use List Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06675f8e-d12d-47a6-86be-ff5eb4c9a80c",
   "metadata": {},
   "source": [
    "Let's try out `generate_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9def1d5-8d64-40b0-b150-4381fc613d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_list(3, 'programming languages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e44408-88ac-4a41-a158-2304bb6ca530",
   "metadata": {},
   "source": [
    "It looks to be working as expected. Let's capture the response and ensure that it is actually a literal Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f34857e-282c-4c36-b17e-41f5978ca635",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_qualities = generate_list(4, 'good qualities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf6631-7477-46d5-a888-4dad6b494302",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(good_qualities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c750f01c-aa01-4c6d-9f42-d1f97708ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good_qualities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e42c6-a565-4acb-8a90-3e8592765dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for good_quality in good_qualities:\n",
    "    print(good_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ff5af-aebb-46ca-b9b7-af098b7a8436",
   "metadata": {},
   "source": [
    "Here we loop through several values for `n` and `topic` to generate a few different lists, and then loop through them with some print statements to ensure it is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a631387-8916-40f5-a406-c492ce393afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [3, 6, 4]\n",
    "topics = ['philosophies', 'technological breakthroughs', 'famous toys']\n",
    "\n",
    "generated_lists = []\n",
    "\n",
    "for n, topic in zip(ns, topics):\n",
    "    generated_lists.append(generate_list(n, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4a13e-0b25-4e94-89d2-04a01a085178",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, topic, generated_list in zip(ns, topics, generated_lists):\n",
    "    print(f'topic: {topic}')\n",
    "    print(f'generated list: {generated_list}')\n",
    "    print(f'n: {n}')\n",
    "    print(f'generated list length: {len(generated_list)}')\n",
    "    print(f'lengths match: {len(generated_list) == n}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de09fb-5527-4a47-bc44-f17a3e0adcfe",
   "metadata": {},
   "source": [
    "As we can see, `generate_list` is producing literal lists of the correct length, without duplicates that contains appropriate items for the provided topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
