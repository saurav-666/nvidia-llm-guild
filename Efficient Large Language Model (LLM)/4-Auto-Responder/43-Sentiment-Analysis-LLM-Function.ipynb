{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8f7516-57f9-471f-8bd9-b080127a688b",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da992d2-2293-4519-8ebb-5a856db69642",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentiment Analysis LLM Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb453e-7613-4dc9-9715-087799586a53",
   "metadata": {},
   "source": [
    "In this notebook you will encapsulate the sentiment analysis functionality you enabled in the previous notebook with your LoRA fine-tuned GPT8B model into an LLM function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c693621-8a5e-4ee0-a324-694e87c43fa5",
   "metadata": {},
   "source": [
    "![Sentiment LLM function](images/sentiment_llm_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f27af-228b-4e0e-b718-8345cb50f511",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acdf224-2849-43af-9265-e33d221b10b7",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e18c9-1f9e-4f67-8ad8-f5082c95b021",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will:\n",
    "- Create a `get_sentiment` LLM function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e084ec8-042a-456b-bdc9-457739a75344",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12ce63-7179-405b-86cf-03e49f51f354",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807cfa5-a29a-4e8b-ac92-063655341429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from llm_utils.models import LoraModels\n",
    "from llm_utils.nemo_service_models import NemoServiceBaseModel\n",
    "from llm_utils.llm_functions import make_llm_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b1c11-09be-40f1-aceb-09535d298f0b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c7df4-40ae-40dd-826c-93380de3c175",
   "metadata": {},
   "source": [
    "## List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14eaeea-5961-4bc1-87fd-90fa9bbc2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoraModels.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d25de-1012-4c43-9581-299bfb3aacd8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb091c10-0555-4c85-ac87-fc89471e9375",
   "metadata": {},
   "source": [
    "## Make LLM Function for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d88046-1bbb-4a68-b723-f90d75d2b665",
   "metadata": {},
   "source": [
    "For this exercise, your task is going to be to create an LLM function to encapsulate the sentiment analysis functionality you just enabled with your LoRA fine-tuned GPT8B model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642bf84d-a849-4e74-ab11-b98ce62c3aae",
   "metadata": {},
   "source": [
    "### Load Amazon Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9a331-954c-4451-afee-cd9bb8091bb4",
   "metadata": {},
   "source": [
    "Before you begin your work, let's load the a small 10 sample test set of reviews and their corresponding sentiment labels. Since your LLM function will encapsulate the prompt template for this task, these reviews have not yet been formatted into prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a44226-47a9-4e12-8a4c-0bb020c23297",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_file = 'data/reviews_10.json'\n",
    "with open(reviews_file, 'r') as f:\n",
    "    reviews_with_sentiments = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56b995-8d67-45d3-a6e1-ea55410b4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_with_sentiments[0]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ecc28-2102-4da5-8542-47a77713fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_with_sentiments[0]['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be37ebc-84b2-4d72-947e-db1a010ba12e",
   "metadata": {},
   "source": [
    "### Sentiment Model Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c392c69-5b9d-4c1c-9811-29cdf90688f3",
   "metadata": {},
   "source": [
    "Here is the same GPT8B model instance LoRA fine-tuned for sentiment analysis that you created earlier in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9588aa-c511-4aaa-9566-e2d74d27d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt8b_lora = NemoServiceBaseModel(LoraModels.gpt8b.value, customization_id='a8ddd3ab-f74b-40e6-972a-6c18c4690d7b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec90875-7f6c-4602-b650-11849f060a1d",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517b7cd-edec-4835-a0be-8f749c1b636f",
   "metadata": {},
   "source": [
    "The following `sentiment_prompt_template` is the same prompt template we used in the previous notebook to format text into a sentiment analysis prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebabeb-c7f3-48d1-ab85-447cd0c14e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_prompt_template(text):\n",
    "    return f'Is the overall sentiment of the following review \"positive\" or \"negative\"? {review} Sentiment:'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136c913-5f89-4bb1-bdcf-4610a5c61a07",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0901a33-a010-4229-b79b-11fccc24f167",
   "metadata": {},
   "source": [
    "## Exercise: Make Sentiment LLM Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07080e0-69d2-481c-9c30-20a787c59285",
   "metadata": {},
   "source": [
    "With a model instance and a prompt template function, you're ready to make an LLM function for sentiment analysis called `get_sentiment`. We've provided the scaffolding for your function, as well as a loop over the test data that should work once you've correctly implemented your function.\n",
    "\n",
    "Don't forget to strip white space off your model's responses.\n",
    "\n",
    "Feel free to check out the solution below if you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f284f-e5a9-4592-a88d-50d7c77360b6",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db540d6-97d9-4b0b-9793-84ee312e3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment = 'TODO' # `get_sentiment` should be an LLM function that can return the sentiment of a passed-in review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b69fe60-30b8-490b-85e4-16716b8be9e7",
   "metadata": {},
   "source": [
    "### Test Your Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf55a691-c482-45bc-99d7-9773e48ed6e0",
   "metadata": {},
   "source": [
    "After you've successfully created `get_sentiment` the following cell should run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed31fd-69eb-4d57-896e-5abd03f8d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review_with_sentiment in reviews_with_sentiments:\n",
    "    review = review_with_sentiment['review']\n",
    "    sentiment = get_sentiment(review, tokens_to_generate=1)\n",
    "    print(f'Sentiment: {sentiment}')\n",
    "    print(f'Label: {review_with_sentiment['sentiment']}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4bb93-a8af-493d-8309-c97586956481",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015faf1-f5b6-4d5c-89a1-a33e8d5fb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(response):\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420a617-9ce3-4f64-810f-646bad81ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment = make_llm_function(gpt8b_lora, sentiment_prompt_template, postprocessor=strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308bd0d4-9cb3-49a9-8570-57b54c528f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review_with_sentiment in reviews_with_sentiments:\n",
    "    review = review_with_sentiment['review']\n",
    "    sentiment = get_sentiment(review)\n",
    "    print(f'Sentiment: {sentiment}')\n",
    "    print(f'Label: {review_with_sentiment['sentiment']}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
