{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932e3a28-f5b5-497d-be11-3f29417a01a2",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060b21a-f4fd-4631-9043-e60268d35240",
   "metadata": {},
   "source": [
    "# Project: Automatic Email Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d57923-ec9e-4559-a129-b44feac27044",
   "metadata": {},
   "source": [
    "Eariler in the workshop you undertook several tasks to create synthetic customer emails that included a variety of specific details appropriate to a fictitious company and its industry. In this project, you will again use several prompt-engineered and fine-tuned models, including the sentiment analysis and extractive QA fine-tuned models you recently fine-tuned, but this time in the service of creating automatic responses to the synthetic customer emails you generated earlier in the workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91614346-68bf-48cc-abaa-d0d4850bfad9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad297f0-7f40-49b9-99e0-79382cf0534e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5409d57-d29b-47a4-ad64-9233d17760a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from llm_utils.nemo_service_models import NemoServiceBaseModel\n",
    "from llm_utils.models import Models, LoraModels\n",
    "from assessment import assess\n",
    "from llm_utils.postprocessors import strip\n",
    "from llm_utils.llm_functions import (\n",
    "    autorespond_to_customer as solution_autorespond_to_customer,\n",
    "    get_sentiment,\n",
    "    make_llm_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e3194-44c2-4e32-9378-ea7551f1168a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671e327e-b625-4ca3-9b24-c505db87a79e",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7a7984-41c2-4b58-a099-0439dde3e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "Models.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c555d33-be7c-449f-acf4-c5bbcdf661cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoraModels.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c27349-b9f8-48b0-bcf7-75628ecca700",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc571ca-872f-4766-abd3-e6041ba5ffe4",
   "metadata": {},
   "source": [
    "## Project Main Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5d232-000b-4d61-b7df-b3e0041f67d2",
   "metadata": {},
   "source": [
    "![Auto Respond](images/auto_respond.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c120b7e2-a516-4f04-9220-1dad4b6f5b65",
   "metadata": {},
   "source": [
    "The main objective of this exercise is to generate response emails of roughly 200 characters to the customer emails you synthetically generated earlier in the workshop.\n",
    "\n",
    "In service of generating an appropriate response you will need to ascertain the following from the customer emails and then use them appropriately in the response email:\n",
    "\n",
    "- Overall sentiment of the customer's email.\n",
    "- The name of the person who sent the email.\n",
    "- The product of focus in the customer's email.\n",
    "- The store location where the customer purchased their product.\n",
    "\n",
    "The result of your work should be a function `autorespond_to_customer` that expects a single `email` argument (a customer_email) for which it generates and returns an appropriate response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af70de7-3252-4645-ab94-cd1c36627eeb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c98b0-3be6-43e6-b3df-2eb897ec0140",
   "metadata": {},
   "source": [
    "## Exercise Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5b5cd-1f0e-4528-9ab7-fd512f378c87",
   "metadata": {},
   "source": [
    "Below is an example of the kind of email response your `autorespond_to_customer` function should generate. Notice especially how the response takes into account the sentiment of the customer email (by either thanking the customer or apologizing to them) and how its response includes the sender name, product, and store location details from the cutomer email.\n",
    "\n",
    "First we'll provide 2 synthetic customer emails to generate auto responses for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98525555-56a6-4dbd-803f-9b51fb80bdfc",
   "metadata": {},
   "source": [
    "### Negative Customer Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da700c7-b5e1-460c-ac2d-b84a6ee4668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_bike_seat_berkeley_josh = \"\"\"\n",
    "Heyo,\n",
    "\n",
    "I recently got a SuperSeater bike seat for my toddler from your store in Berkeley and one of the seatbelt straps \\\n",
    "appears to be frayed pretty bad and I think it may have come that way. One of my neighbors actually pointed it \\\n",
    "out to me and they mentioned it might be a safety issue. I'm wondering if it's something you can repair, \\\n",
    "or if you can replace the bike seat for me so I can feel safe hauling my kid around? This seems pretty \\\n",
    "dangerous right now.\n",
    "\n",
    "Best,\n",
    "Josh\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359bdcb-2e63-4a9b-826c-2fff7c6ca66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_to_negative_bike_seat_berkeley_josh = solution_autorespond_to_customer(negative_bike_seat_berkeley_josh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2153ba7-669b-458c-bad2-b33ec6886dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_to_negative_bike_seat_berkeley_josh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b318b-6407-42c5-88fb-befaccddf59b",
   "metadata": {},
   "source": [
    "### Positive Customer Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a93684-ce88-471b-9025-a24e5bbe23ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cruiser_oceanside_marcello = \"\"\"\n",
    "Good Day,\n",
    "\n",
    "I've been riding my new Starlight Cruiser for a couple weeks now and just want to report that I've \\\n",
    "been having a blast. I've been spending so much less time in my car and all I can say is \\\n",
    "I can't believe I waited so long! I'd like to chat with someone at your store in \\\n",
    "Oceanside about setting up regular tune-up appointments. Can you help me out with that?\n",
    "\n",
    "Best,\n",
    "Marcello\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a92bf3-c5e1-48bd-b481-d411d28c4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_to_positive_cruiser_oceanside_marcello = solution_autorespond_to_customer(positive_cruiser_oceanside_marcello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab6281-92a3-40db-81ca-79f12da761af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_to_positive_cruiser_oceanside_marcello)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122e3dd-431c-4ebc-98d0-6b1ae0838a7d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a1a92-2407-4543-9a7a-1fd41aeb86b1",
   "metadata": {},
   "source": [
    "## Project Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd477db-b649-4416-b976-72c58178400b",
   "metadata": {},
   "source": [
    "![Auto Details](images/auto_details.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54595387-2840-44e3-bb8c-7a1e97278424",
   "metadata": {},
   "source": [
    "Your `autorespond_to_customer` function will be performing several specific tasks:\n",
    "- Getting the sentiment of the customer email.\n",
    "- Extracting the customer name from the email.\n",
    "- Extracting the product in question from the email.\n",
    "- Exracting the location where the product in question was purchased from the email.\n",
    "- Generating a respone email using all of the pertinent details above.\n",
    "\n",
    "With that in mind, we've provided the definition of `autorespond_to_customer`, and it will be your task to implement each of its component LLM function parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aabceb-6ce8-418b-8507-37afbd7f6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = 'StarBikes'\n",
    "def autorespond_to_customer(email):\n",
    "    sentiment = get_sentiment(email, tokens_to_generate=1)\n",
    "    name = extract_name(email)\n",
    "    product = extract_product(email)\n",
    "    location = extract_location(email)\n",
    "\n",
    "    response = generate_customer_response_email(company, name, sentiment, product, location)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52021379-a75c-4cc9-8486-5b5597e07df7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f653f06-58e6-4591-acb9-ee6924b2be23",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf4d04-af7a-43ca-bb0a-37ad65ec946b",
   "metadata": {},
   "source": [
    "Earlier in the workshop, you created the `get_sentiment` LLM function, which uses a few-shot prompt engineered GPT8B model. We've imported it for your use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48a079-cd64-4202-b9b2-34a29df9df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment('I am happy', tokens_to_generate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa08893-d39e-4fc2-90b3-b4b9ad2e3a19",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba02349-3c82-4525-9cc4-fad9b416c916",
   "metadata": {},
   "source": [
    "## Entity Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc5a2433-1a97-4def-a10f-2746b43349f5",
   "metadata": {},
   "source": [
    "For the various entity extraction tasks you will be using the LoRA fine-tuned GPT8B model for extractive QA tasks that you created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aeb9ed-bae5-4314-96f1-cc8c60647803",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_model = NemoServiceBaseModel(LoraModels.gpt8b.value, customization_id='ebd552dc-a050-4987-afca-9136d45fbad1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad818b6-9583-4bdb-84cd-303f26ec2a5c",
   "metadata": {},
   "source": [
    "As you'll recall, `extractor_model` was fine-tuned using the following prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552aa5b6-0683-429e-985e-077b4535351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_template(text, question):\n",
    "    return f'{text}\\n{question} answer:'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32fb3c4-2a8b-491b-aa73-fe303916f9d5",
   "metadata": {},
   "source": [
    "You will be working with this model, in addition to creating appropriate prompt templates and postprocessors, to create 3 LLM functions: `extract_name`, `extract_product`, and `extract_location`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d5359c-1a10-47a8-9c2c-3c9c44d9e6fc",
   "metadata": {},
   "source": [
    "### Extract Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c90160-f1a7-4fe8-aaf0-dc1f4de8d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_template(email):\n",
    "    return 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272caf63-cb02-4caf-a768-7836e08774d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_postprocessor(name):\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f3fdfd-6073-49e8-bb79-d6aac3056761",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_name = make_llm_function(extractor_model, extract_name_template, postprocessor=extract_name_postprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19ba43-4ece-4be3-8554-e8c53c5e8cd9",
   "metadata": {},
   "source": [
    "### Extract Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c3272-2cee-4053-9c96-f70dcfc5e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_template(email):\n",
    "    return 'product'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ec993-9868-4de5-b782-e568fe8ae496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_postprocessor(product):\n",
    "    return product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3fbbda-4975-4643-bf14-287154b86d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_product = make_llm_function(extractor_model, extract_product_template, postprocessor=extract_product_postprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f19703-6e96-4e2c-b743-6a4ce64f7d7d",
   "metadata": {},
   "source": [
    "### Extract Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e00a05c-b37c-4be8-a85f-885bf98afe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location_template(email):\n",
    "    return 'location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fec695-31ee-4037-8faa-7e463a009649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location_postprocessor(location):\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4b0d7-8198-4377-adc6-f527aa8858fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_location = make_llm_function(extractor_model, extract_location_template, postprocessor=extract_location_postprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd1077-6825-4ecf-b0f7-64f10146f084",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b514376-88c5-4223-8f45-0cbca1079635",
   "metadata": {},
   "source": [
    "## Response Email Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d101ee2-356d-4f23-968c-2003ebd95d7e",
   "metadata": {},
   "source": [
    "After analyzing the sentiment of the customer email and extracting all relevant details, you'll need to pass them to an LLM function you will create to generate the response to the customer. For this LLM function you will be using GPT43B with the provided prompt template, which you will need to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff6c61-77a9-480f-a943-3e698dfebc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_response_model = NemoServiceBaseModel(Models.gpt43b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be119c01-9d25-48b5-85c7-869a34e930c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_response_email_prompt_template(company_name, recipient_name, sentiment, product, store_location):\n",
    "    return 'email'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66968e30-51ad-4c73-b66c-64c8a497a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_customer_response_email = make_llm_function(email_response_model, customer_response_email_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52587d1-5f3f-4368-8545-6bc500539cbe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c2ed1c-26b1-450d-bdf9-aef9790b5bd0",
   "metadata": {},
   "source": [
    "## Load Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71327359-4a35-4513-a39b-0b5491e744d5",
   "metadata": {},
   "source": [
    "Before beginning your work, load the synthetic customer emails from the previous notebook. We've provided our solution emails for your use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6d425-e35e-4dbe-af83-69d806d047ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/solution_emails.json', 'r') as f:\n",
    "    customer_emails = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd9822-c65c-42e0-90d3-2fec954b4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(customer_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167bcd7-52c4-4053-afb1-04b977894a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_emails[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d90fdb-f518-4de3-8064-18fb4f8ee9c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd470c-204d-4ff3-a60c-cd178724e226",
   "metadata": {},
   "source": [
    "## Company Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4295e-7b86-4537-ab8e-7c19f5469e65",
   "metadata": {},
   "source": [
    "We will again use the fictitious bike company StarBikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b656d-3c7b-46ab-827f-c098dfa280ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = 'StarBikes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5236a723-b5c8-49a9-b171-0c10eb75f51f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d3684-3b84-4a10-8a1e-033873662903",
   "metadata": {},
   "source": [
    "## Assessing Your Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565d2d4-20a2-48d8-9b61-842e68ff2ced",
   "metadata": {},
   "source": [
    "If you are successfully able to implement a working `autorespond_to_customer` function you will earn a certificate of competency for the workshop. In order to assess your work, you will be passing your `autorespond_to_customer` function to our provided `assess` function.\n",
    "\n",
    "Behind the scenes, `assess` will pass `autorespond_to_customer` 3 customer emails and then check that your response matches the specifications we've described in this notebook. In order to pass the assessment, your responses will need to contain fewer than 3 mistakes.\n",
    "\n",
    "Since we've already implemented the scaffolding for `autorespond_to_customer` we can try the assessment out now, although it is definitely going to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf40a40-b352-4711-8bfc-088aad73bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assess(autorespond_to_customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6d7789-7fb2-492a-b8bf-426c16e97cac",
   "metadata": {},
   "source": [
    "### Earning a Workshop Certificate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df7273c-f5ce-4a72-9908-3721da036821",
   "metadata": {},
   "source": [
    "Once you have successfully passed the assessment, see the instructions at the bottom of the notebook for how to get credit for your work and generate a certificate of competency for the workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f276d-5933-4106-a0d4-9a27cef42e60",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9c212-c1a4-478b-b9cc-48df9f46e2ad",
   "metadata": {},
   "source": [
    "## Begin Your Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596cdf81-c2a7-4ec5-a908-a20d88a3df79",
   "metadata": {},
   "source": [
    "If you're up for a big challenge, you can jump right in: we've provided you with everything you need to complete the assessment.\n",
    "\n",
    "If you'd like additional support, expand the _Exercise Walkthrough_ section below to work through the assessment step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2f5e1b-d4eb-472a-a5ad-d3a4bd5bad5c",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f28dc4-1aef-45d8-b6d4-5a0c9ac084c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7dbc828-7fe8-4c60-96f4-9c21f8a875dd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e956147-397d-482b-9033-d459d50fd9f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exercise Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb39f88-d8ba-4238-b012-b186985187d5",
   "metadata": {},
   "source": [
    "Let's look again at the `autorespond_to_customer` function we need to make functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350ad8c-1bc1-4b72-9699-1d364a846bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autorespond_to_customer(email):\n",
    "    sentiment = get_sentiment(email, tokens_to_generate=1)\n",
    "    name = extract_name(email)\n",
    "    product = extract_product(email)\n",
    "    location = extract_location(email)\n",
    "\n",
    "    response = generate_customer_response_email(company, name, sentiment, product, location)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0154ab0-3b12-4feb-919a-7045062bd8a3",
   "metadata": {},
   "source": [
    "With this function definition as our guide, we will tackle each of the component LLM functions one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b597a9-d867-4709-8abe-74399a8d7f2b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a1e2b5-0a2e-4451-abb5-fc768aa6d60e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23e00c-20fd-438e-b1b3-3d6ce3e0db6e",
   "metadata": {},
   "source": [
    "![Sentiment LLM function](images/sentiment_llm_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eef01a-9f13-4d79-977d-b94152e97c0c",
   "metadata": {},
   "source": [
    "You already implemented the LLM function `get_sentiment` and we have imported it for you, so all we need to do is confirm that it is working as expected by trying it out with a few of the `customer_emails` we loaded from file above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4ecdf-e4f2-463c-81a7-58cda16a043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_email in customer_emails[:5]:\n",
    "    print(get_sentiment(customer_email, tokens_to_generate=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5809311-fb93-402c-9a5d-f3251f19c96c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565ce01-2692-4c04-93bb-00e6b96bed59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Entity Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d780aa7-3385-4f01-82d4-53df9a9482fb",
   "metadata": {},
   "source": [
    "For the entity extraction tasks you will be using the GPT8B model you LoRA fine-tuned for extractive question answering in the previous notebook, which we instantiate for you here. We've also provided the prompt template associated with the extractive QA task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd964791-97f8-49f8-846c-d7c06900fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_model = NemoServiceBaseModel(LoraModels.gpt8b.value, customization_id='ebd552dc-a050-4987-afca-9136d45fbad1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa22c96-f8f9-4eb0-a561-72ff79b3857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_template(text, question):\n",
    "    return f'{text}\\n{question} answer:'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1646a12-d2ed-4197-8301-98dd91b1c6f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Entity Extraction Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8876af-e7a4-48a6-8d4e-cf5344629e4a",
   "metadata": {},
   "source": [
    "Up to now you've been performing extractive QA with the SQuAD dataset. Let's take a look at how we might use the model to extract details of interest to us, in this case a store location, from a synthetic customer email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3069ac61-e368-44ba-8061-4fc239312255",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Heyo,\n",
    "\n",
    "I recently got a SuperSeater bike seat for my toddler from your store in Berkeley and one of the seatbelt straps \\\n",
    "appears to be frayed pretty bad and I think it may have come that way. One of my neighbors actually pointed it \\\n",
    "out to me and they mentioned it might be a safety issue. I'm wondering if it's something you can repair, \\\n",
    "or if you can replace the bike seat for me so I can feel safe hauling my kid around? This seems pretty \\\n",
    "dangerous right now.\n",
    "\n",
    "Best,\n",
    "Josh\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e37a75-8100-48c4-8652-36005257dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_question = 'Where is the store located?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32042a13-63c9-4c02-8336-01a475db47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = extract_template(text, extract_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef080a42-1e00-455e-b356-ceb0677c81a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b923a-e8ba-410b-b7c4-96395b56f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_model.generate(prompt).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8862c-4a07-4d86-95ab-484aa2b0fd02",
   "metadata": {},
   "source": [
    "At a glance at least, it looks like the model you fine-tuned might well be up for the currect extractive QA tasks you would like to address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba315393-0918-4e3e-8420-db54407b2ec6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e4adb-34a2-4068-8e2b-acdcd9aa8c0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Name Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b9e44-3a4f-43c7-8958-be58957fbd70",
   "metadata": {},
   "source": [
    "Since we would like to reuse the `extractor_model` for 3 different extraction tasks (name, product, and location) and create 3 different LLM functions we will need for each of the 3 extraction tasks to create an LLM function using the model that has an appropriate prompt template, and optionally, a post-processor.\n",
    "\n",
    "Let's begin with name extraction. We will provide the entire process by which we created this LLM function before giving you a chance to build your own extraction LLM functions for products and locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b0394-d150-4df0-96cb-6b2d0f059da1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3380d-396a-4334-af89-502ffaea9cc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Name Extraction Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54097285-b659-4317-ac95-bb64ba079da1",
   "metadata": {},
   "source": [
    "To create a name extraction prompt template we are going to reuse the prompt template that the extraction model expects, shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043de138-0247-4fad-af65-ab4f733a4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_template(text, question):\n",
    "    return f'{text}\\n{question} answer:'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a9fe0-ee72-4b4d-86c8-ddcfe0e0f852",
   "metadata": {},
   "source": [
    "Knowing that we want to extract the name of who sent a given email, we can hardcode in a question to extract this name, leaving the rest of the expected prompt template intact. Below is a prompt template we prompt engineered for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b272930e-a992-45fc-a2ed-b246bb2b2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_template(text):\n",
    "    return f'Email: {text}\\nWhat is the name of the person, if any, that sent the email? answer:'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b8ed6d-f684-4e2a-85ef-7f1691058e50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e4c0d-1676-42ba-9e57-2ab2e204364c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Name Extraction LLM Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e23e09-25e4-491b-ba24-2fadf2ebc52c",
   "metadata": {},
   "source": [
    "![Extract name](images/extract_name.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9161a-d3ff-4a27-a21f-387cd5d59f13",
   "metadata": {},
   "source": [
    "Now with `extractor_model` and `extract_name_template` we can create an LLM function `extract_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e10a4d8-6346-49e3-8315-91a038defb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_name = make_llm_function(extractor_model, extract_name_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2337ad33-129a-49e2-8b2a-fd4b982388ff",
   "metadata": {},
   "source": [
    "Let's try it out on some customer emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6adbd-0560-464a-8750-a2c23a5d8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_email in customer_emails[:15]:\n",
    "    response = extract_name(customer_email)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2f19c-7273-4740-99fd-980e009b4f3b",
   "metadata": {},
   "source": [
    "These look pretty good except that there appears to be white space that needs stripping, and, in a couple instances we got back the the name `'Hi'` or `'Hi Starbikes'` which are clearly not acutal names. Let's investigate further by looking at the emails when we get either of these responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ee4e6-75af-4714-804e-18f987c1e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_email in customer_emails[:15]:\n",
    "    response = extract_name(customer_email)\n",
    "    if 'hi' in response.lower() or 'StarBikes' in response:\n",
    "        print(response)\n",
    "        print(customer_email+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141f77f-5022-42d3-98ff-9f93196911c1",
   "metadata": {},
   "source": [
    "In two of the cases, it looks like the customer email doesn't actually include a name. In these scenarios it makes sense the model was unable to extract a customer name.\n",
    "\n",
    "In the 3rd case we can only guess why the model responded with `'Hi StarBikes'` instead of `Virginia`, but one guess is that it thought the former more of a human full name compared to the latter which might be understood as the name of a state.\n",
    "\n",
    "Observing that our model does a good job at this task, but not a perfect one, we will want to take care in postprocessing to handle scenarios where we don't get back a customer name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276cd22-7d52-48fc-855e-a1dc4c46d199",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a966cbc-c189-49ab-ac7f-744506acc3ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Name Extraction Postprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f14fbf-ee9e-4aaf-ba0b-d2c117488932",
   "metadata": {},
   "source": [
    "Let's create a postprocessor function to address the issue above. The following `get_safe_name` function strips white space but also checks to see if a non-sensical name like `'hi'` is being extracted, in which case it returns a default value `'a customer who didn\\'t give us their name'`. There are some additional non-sensical names included in the `unsafe` set that we discovered working more in depth with this model, so we've gone ahead and provided them for you here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2796de-46d8-4703-84e7-b006d398be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_safe_name(name):\n",
    "    unsafe = {'no', 'i', 'hello', 'hi', 'greetings', 'starbikes', 'dear'}\n",
    "    name_words = name.strip().lower().split()\n",
    "    if any(word in unsafe for word in name_words):\n",
    "        return 'a customer who didn\\'t give us their name'\n",
    "    else:\n",
    "        return name.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b93d2-6eab-49a8-96d3-4f08d72b51c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e9962a-25ff-403e-bbd1-c4eb96d5f743",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Name Extraction LLM Function With Postproceesor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e296712-ddf8-4a8a-84de-8a127493a704",
   "metadata": {},
   "source": [
    "Let's recreate the `extract_name` LLM function, but this time using the `get_safe_name` postprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4c527-9e33-4781-9ce0-5f843174dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_name = make_llm_function(extractor_model, \n",
    "                                 extract_name_template, \n",
    "                                 postprocessor=get_safe_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc0088-7191-4a3f-9005-c2e5501cc04e",
   "metadata": {},
   "source": [
    "And now let's try the updated LLM function on several emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cfa0a0-997a-4a5e-934c-cc6764cab3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_email in customer_emails[:15]:\n",
    "    print(extract_name(customer_email))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f57060-afa9-47a0-be21-6b815df99020",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b2368-1a18-4cef-b40a-fe7bcb628c72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Product Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6fe94-98ca-408a-915b-cfb48a5987eb",
   "metadata": {},
   "source": [
    "Using a similar approach, create the `extract_product` LLM function we need for use in our `autorespond_to_customer` email. After observing an initial implementation, consider adding a postprocessor to handle any unexpected responses by returning a default value like the string `'product'`.\n",
    "\n",
    "Feel free to check out the *Solution* below if you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6fc9ff-a7c8-4d64-b90a-202e913ba529",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859cd8c-c178-4c55-b19c-bb707a84f2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9fd6466-cdd1-447a-ba00-a191128c6241",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1283a-74f5-49c4-9671-b103a7a7355a",
   "metadata": {},
   "source": [
    "### Product Extractor Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142947ca-86eb-4d3d-a283-75cf4b94c658",
   "metadata": {},
   "source": [
    "Knowing that we want to extract the name of who sent a given email, we can hardcode in a question to extract this name, leaving the rest of the expected prompt template intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae31d4-00be-4a87-aa44-200960658dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_template(text):\n",
    "    return f'{text}\\nWhat StarBikes product is this person writing about? answer:'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8741e-ecdd-4b62-a58f-545f102330db",
   "metadata": {},
   "source": [
    "### Product Extractor Postprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3964cd68-b2a3-4526-b93e-9d92a8ed8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_safe_product(product):\n",
    "    return 'product' if 'starbikes' in product.strip().lower() else product.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8054fea2-c956-4bff-b7b0-2d7fb465ef04",
   "metadata": {},
   "source": [
    "### Product Extractor LLM Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc4b2d-a629-4d54-bff1-7cdaa4668aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_product = make_llm_function(extractor_model, \n",
    "                                    extract_product_template, \n",
    "                                    postprocessor=get_safe_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1ed8a-44f9-43b1-a5b7-55edae96f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_email in customer_emails[:15]:\n",
    "    response = extract_product(customer_email)\n",
    "    print(response)\n",
    "    if 'StarBikes' in response:\n",
    "        print(customer_email+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7af36-2b96-4960-b070-882d88729b53",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf1abe-503f-4a33-9fcc-2b8f3205d572",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Location Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff1f286-69de-40b9-b90d-7c39b9f85521",
   "metadata": {},
   "source": [
    "![Extract location](images/extract_location.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18d552a-ad6f-490b-9a38-5c9803af5226",
   "metadata": {},
   "source": [
    "Now create the `extract_location` LLM function. After observing an initial implementation, consider adding a postprocessor to handle any unexpected responses by returning a default value like the string `\"their store's location\"`.\n",
    "\n",
    "Feel free to check out the *Solution* below if you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4dbab-711c-44d9-81e9-5063c3fb88e8",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4291b-0b85-447c-891d-5fdf34ab8002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b4ed84-a9a9-46f3-8e7e-fb9719bd27aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0c3809-e97e-4866-89ff-5605acaabb4e",
   "metadata": {},
   "source": [
    "### Location Extractor Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc3dbd-100d-472b-9fb8-1dd64bfa62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location_template(text):\n",
    "    return f'{text}\\nWhere was the store located? answer:'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91105e76-6b27-4414-9159-f4b9d72f3f5d",
   "metadata": {},
   "source": [
    "### Location Extractor Postprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c7478-4c71-404e-a3c9-6957f1816e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_safe_location(location):\n",
    "    return 'their store\\'s location' if location.strip().lower() == 'no' else location.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66416c3a-da8e-4e38-a89b-15e150c64c3a",
   "metadata": {},
   "source": [
    "### Location Extractor LLM Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35250c46-af05-4f0e-bbc2-b0864c5b5e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_location = make_llm_function(extractor_model, \n",
    "                                     extract_location_template, \n",
    "                                     postprocessor=get_safe_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a60f21-a893-44dd-b666-1e19c07f51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_email in customer_emails[:15]:\n",
    "    print(extract_location(customer_email))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c041be-a353-4832-b2c6-1647c5c8787a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876ba3d-c179-446c-a8c6-13246972fc0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Write Response Email LLM Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713a2f9-e3dd-471f-bdab-1864f074c2d4",
   "metadata": {},
   "source": [
    "![Write response](images/write_response.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae03ac65-8855-43c7-a354-3562108c9ccb",
   "metadata": {},
   "source": [
    "Now it's time to put your prompt engineering skills to the test by creating a `generate_customer_response_email` LLM function. Your function should accept as arguments the sentiment of the customer emails as well as the 3 extracted details (name, product and location) and should respond appropriately to the sentiment of the customer email, reusing the customer name, product and location used in the cutomer email.\n",
    "\n",
    "We provided an [example of this functionality earlier in the notebook](#Exercise-Example) if you'd like to review it now.\n",
    "\n",
    "Provided for you below is the model for you to use and the scaffolding for the prompt template you should use. As a reminder, `company_name` was defined eariler in the notebook and should be available for your use here.\n",
    "\n",
    "Feel free to check out our *Solution* below if you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eeb1d7-24ab-41cc-ac50-641f32545f10",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76cc88e-97b7-413d-bb7d-f7ad7bad7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_response_model = NemoServiceBaseModel(Models.gpt43b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3afdc-af9f-4d2b-9f4d-9e50215b3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_response_email_prompt_template(company_name, recipient_name, sentiment, product, store_location):\n",
    "    return 'email'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6aa087-eced-4e63-bde7-2350ded4998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_customer_response_email = make_llm_function(email_response_model, customer_response_email_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b07b6-b6bc-4299-b7e9-a0b9726688f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbbcc20-5002-4a21-b648-f10abdd8446a",
   "metadata": {},
   "source": [
    "### Customer Response Email Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b4c9c7-211a-429d-bef9-fd8d2a01a69b",
   "metadata": {},
   "source": [
    "We iteratively engineered the following prompt template for the customer response email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a592b-1116-45f1-99a6-76fdafbc4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_response_email_prompt_template(company_name, recipient_name, sentiment, product, store_location):\n",
    "    return f\"\"\"\\\n",
    "Write a customer response email of 200 words.\n",
    "\n",
    "Context: {recipient_name} just sent an email expressing a {sentiment} sentiment about our company {company_name}. \\\n",
    "Their email was about a {product} they purchased in {store_location}. We want to send a response email emphathizing with \\\n",
    "their experience and if appropriate, telling them that someone from {store_location} will be contacting them soon.\n",
    "\n",
    "Instructions: Write a reply email using the following steps:\n",
    "\n",
    "1) Greet {recipient_name} professionally by their name. If their name is 'the customer' address them as \"Dear Customer\".\n",
    "\n",
    "2) Depending on the sentiment expressed in their email (stated above), empathize as a friend would about their experience with their {product}.\n",
    "\n",
    "3) Tell the customer that an employee from our store in {store_location} will contact them soon \\\n",
    "to followup with them in more detail. NEVER ask the customer to contact us. NEVER ask the customer for thier contact information.\n",
    "\n",
    "4) Write a professional closing signed by \"{company_name} Customer Support Team\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335feee7-e441-4821-8273-e3780b6eaca9",
   "metadata": {},
   "source": [
    "### Customer Response Email LLM Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a1799-d060-4c17-a82f-e9133efa107e",
   "metadata": {},
   "source": [
    "Using the above model, prompt template, and `strip` postprocessor, we created the following LLM function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76dfa0-f735-402c-8812-5c4912b6efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_customer_response_email = make_llm_function(email_response_model, \n",
    "                                                     customer_response_email_prompt_template, \n",
    "                                                     postprocessor=strip) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a6d53-d224-466d-b4db-4fdaa0029128",
   "metadata": {},
   "source": [
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e6155-90d5-4767-80f5-50b6552df17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_response_email = generate_customer_response_email('StarBikes', 'Stella', 'negative', 'Cruiser', 'Oakland')\n",
    "print(customer_response_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a4692-8db4-45a6-bb87-388c243676bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5325ba3-0f68-4de4-af6c-f5f65d965adc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Autorespond to Customer Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a706c0a-cf33-4d1d-aaf6-1a9b548778b7",
   "metadata": {},
   "source": [
    "![Auto Details](images/auto_details.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ddbda2-b0b5-4508-ba73-8837aaef0f6f",
   "metadata": {},
   "source": [
    "Now that we've created all the component LLM functions for `autorespond_to_customer` let's try it out on a few customer emails.\n",
    "\n",
    "First we'll provide the `autorespond_to_customer` definition from earlier in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b5bac-d562-4c6b-919d-a85bdccb627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = 'StarBikes'\n",
    "def autorespond_to_customer(email):\n",
    "    sentiment = get_sentiment(email, tokens_to_generate=1)\n",
    "    name = extract_name(email)\n",
    "    product = extract_product(email)\n",
    "    location = extract_location(email)\n",
    "\n",
    "    response = generate_customer_response_email(company, name, sentiment, product, location)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab8046f-d570-411c-82a2-aa5265ff28b1",
   "metadata": {},
   "source": [
    "Now we'll try it on a few customer emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08025109-7aa0-447b-8631-7d943b743ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_email in tqdm(customer_emails[:4]):\n",
    "    customer_response_email = autorespond_to_customer(customer_email)\n",
    "    print(customer_email+'\\n\\n')\n",
    "    print(customer_response_email+'\\n---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f30f42-2a9c-4038-bcbe-6e10d3994215",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dfc926-3d91-4793-8935-30fc77a1e7c7",
   "metadata": {},
   "source": [
    "# Workshop Final Assessment and Certificate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3c00c-67ab-4803-a737-fc0bca133ea1",
   "metadata": {},
   "source": [
    "If you've successfully been able to implement a working `autorespond_to_customer` function you will earn a certificate of competency for the workshop. In order to assess your work, you pass your `autorespond_to_customer` function to our provided `assess` function.\n",
    "\n",
    "`assess` will pass `autorespond_to_customer` 3 customer emails and then check that your response matches the specifications we've described in this notebook. In order to pass the assessment, your responses will need to contain fewer than 3 mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2115903-8f05-427c-93e7-d0c87b8c02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "assess(autorespond_to_customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b7aa1-5580-43fd-804b-4850e16a2f43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a10fd66-8eda-40e8-8ed5-a7723983355b",
   "metadata": {},
   "source": [
    "## Get Credit for Your Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be1997-0ce4-4601-b88e-b0808098e1ae",
   "metadata": {},
   "source": [
    "If you've made it this far, congratulations! You did a lot of hard work today and your efforts have paid off.\n",
    "\n",
    "Assuming you ran `assess(autorespond_to_customer)` above and got a message saying you passed, you can get a certificate of competency for the course.\n",
    "\n",
    "In your web browser, return to the page where you launched this interactive environment and click the check-mark `ASSESS TASK` button. After a few seconds you will get a congratulatory message with instructions for receiving your certificate in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1fcc7-0429-4433-b46b-80e77fa1fbf8",
   "metadata": {},
   "source": [
    "![assess](images/assess.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
