{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8f7516-57f9-471f-8bd9-b080127a688b",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da992d2-2293-4519-8ebb-5a856db69642",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LoRA for Extractive Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb453e-7613-4dc9-9715-087799586a53",
   "metadata": {},
   "source": [
    "In this notebook you will fine tune GPT8B with LoRA to perform extractive question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125cd9b-3dda-44a8-bd20-a4f7adcaf7fb",
   "metadata": {},
   "source": [
    "![Extract LoRA](images/extract_lora.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f27af-228b-4e0e-b718-8345cb50f511",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acdf224-2849-43af-9265-e33d221b10b7",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e18c9-1f9e-4f67-8ad8-f5082c95b021",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will be able to:\n",
    "- LoRA fine tune a GPT8B model for extractive question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e084ec8-042a-456b-bdc9-457739a75344",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12ce63-7179-405b-86cf-03e49f51f354",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807cfa5-a29a-4e8b-ac92-063655341429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from llm_utils.models import LoraModels, Models\n",
    "from llm_utils.nemo_service_models import NemoServiceBaseModel\n",
    "from llm_utils.mocks import upload_qa as upload\n",
    "from llm_utils.mocks import create_qa_lora_customization as create_customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b1c11-09be-40f1-aceb-09535d298f0b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c7df4-40ae-40dd-826c-93380de3c175",
   "metadata": {},
   "source": [
    "## List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14eaeea-5961-4bc1-87fd-90fa9bbc2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoraModels.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d25de-1012-4c43-9581-299bfb3aacd8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017a817-edab-4029-abb1-4ed21b094ffb",
   "metadata": {},
   "source": [
    "## Load Train Data From File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa695035-c087-4949-bd10-f7e3c3ac5ed4",
   "metadata": {},
   "source": [
    "We will begin this notebook by loading the train and test prompt and label data we created in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f847fdf-d8d1-4fa9-a1c0-370d489dbba9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365edb41-6558-4c95-8d51-c446b2ab1b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/squad_prompts_and_answers.json', 'r') as f:\n",
    "    prompts_and_answers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0a4e3-3b94-4cbd-bcb1-430c136b5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompts_and_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d783aa1-715b-4131-a0a5-8aed17c77e6d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef7d73-4f92-4050-9410-c72be9d80a41",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7425c3-957f-4843-9854-1776b0571933",
   "metadata": {},
   "source": [
    "In preparation for fine-tuning, let's split the data, which currently contains over 2000 samples. We'll create a training set of 1000 samples, a validation set of 200 samples, and a small test set of 20 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6a405-14d1-4803-84d9-6b24afbaeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = 1000\n",
    "val_n = 200\n",
    "test_n = 20\n",
    "\n",
    "train_end = train_n\n",
    "val_end = train_end + val_n\n",
    "test_end = val_end + test_n\n",
    "\n",
    "train_prompts_and_answers = prompts_and_answers[:train_n]\n",
    "val_prompts_and_answers = prompts_and_answers[train_n: train_n+val_n]\n",
    "test_prompts_and_answers = prompts_and_answers[train_n+val_n: train_n+val_n+test_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97147429-dc7c-4f03-bf0b-103f03886445",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_prompts_and_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146762a2-ee12-40c6-af78-ef98f2a6ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_prompts_and_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7868605-a8f6-45fa-9333-135f88133fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_prompts_and_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd86153b-e9f0-48cb-8d25-e9b43dcf7701",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d32ab3-1ef2-40da-87da-3b8347ef93f1",
   "metadata": {},
   "source": [
    "## Exercise: Format Data Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f11996-0036-4dc3-bb02-2c5438c5e4d8",
   "metadata": {},
   "source": [
    "For this exercise, you will format `train_prompts_and_answers` and `val_prompts_and_answers` for NeMo Service fine tuning.\n",
    "\n",
    "As a reminder, NeMo Service expects that data be in JSON Lines (`jsonl`) format, with each line in the file being in the following format:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87165f3f-c21b-42f0-bb96-3605bb2e7224",
   "metadata": {},
   "source": [
    "```python\n",
    "{\"prompt\": <prompt>, \"completion\": <completion/label>}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f504a1-07e4-4b87-8ee3-48d5fdfb677f",
   "metadata": {},
   "source": [
    "Your task is to populate the `qa_lora_train_data` and `qa_lora_val_data` lists with one dictionary for each data sample in `train_prompts_and_answers` and `val_prompts_and_answers` respectively, formatted as needed for NeMo Service LoRA fine-tuning.\n",
    "\n",
    "If you get stuck, feel free to look at the solution below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d5272-8820-4626-8222-a1012803bcc0",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228acbc5-ffef-400a-948d-e7b838d1115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_lora_train_data = []\n",
    "qa_lora_val_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047247c-e3e0-4202-b808-db0db008d5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40a09225-2b5c-493f-875a-fcdf50153b94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69bf80-265a-4716-91be-062b4ed70dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_lora_train_data = [{'prompt': prompt, 'completion': answer} for prompt, answer in train_prompts_and_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a7aef-d88d-404b-8a11-943b2b3b1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_lora_val_data = [{'prompt': prompt, 'completion': answer} for prompt, answer in val_prompts_and_answers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80be0a-6c9d-446f-acd1-db1fd4500d50",
   "metadata": {},
   "source": [
    "Here we see examples of data well-formatted for p-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e779f-c264-41fc-95f1-94cd1b4488ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_lora_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4aa0f6-193f-46fb-8ac3-ce82a67cfb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_lora_val_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6274e-7aaf-466a-ac31-49e193960edb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d61a403-8c49-43d7-8afb-1fe0718a2553",
   "metadata": {},
   "source": [
    "## Write NeMo Customization Data to File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936cf42-7de2-460d-a6b2-9926d112f366",
   "metadata": {},
   "source": [
    "We will ultimately upload our p-tuning data to the NeMo Service where it can be used for fine tuning. First we need to write it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a979e9-550c-40ff-89b1-6dac49e1dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_nemo_train_filename = 'data/squad_nemo_train_prompts_and_answers_1000.jsonl'\n",
    "qa_nemo_val_filename = 'data/squad_nemo_val_prompts_and_answers_200.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746e9a0-8d4c-4730-b7da-aec2eb6c4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(qa_nemo_train_filename, 'w') as f:\n",
    "    for p_and_a in qa_lora_train_data:\n",
    "        f.write(json.dumps(p_and_a) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c03ed-c9bc-4e69-a261-8dadfd89d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(qa_nemo_val_filename, 'w') as f:\n",
    "    for p_and_a in qa_lora_val_data:\n",
    "        f.write(json.dumps(p_and_a) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ec3ad8-cd27-4b31-b574-41ee33be9274",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a36016-6719-4481-8ff7-2ad47fa61982",
   "metadata": {},
   "source": [
    "## Upload Data to NeMo Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71659c-7d75-4a14-a199-2fdd512fa9cb",
   "metadata": {},
   "source": [
    "With the data written to file in JSON lines format, we can now upload it to NeMo Service. As we did earlier, we will mock this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8453ff-c20f-49f6-9b25-03f6ef61555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_response = upload(qa_nemo_train_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c912b4a-0d1a-453b-bcdd-9446208ac820",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38837e-fd74-400a-a089-eaf140373d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_response = upload(qa_nemo_val_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f121d-964e-47ae-8009-04e45083e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a802b9-5b52-43d8-9511-ecaf245338bf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b910e3da-22ee-44d3-b782-00e4045809ff",
   "metadata": {},
   "source": [
    "## Exercise: LoRA Fine-tune GPT8B for Extractive QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2dc0a-6580-431f-8b95-a5e286f63b33",
   "metadata": {},
   "source": [
    "For this exercise you will perform LoRA fine-tuning on GPT8B with the training and validation data you just wrote to file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601468fe-6194-44bb-a0c6-12a4200469db",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe61bdd6-d5f4-44b4-a5c1-b295548ed993",
   "metadata": {},
   "source": [
    "Correctly launch a (mock) LoRA customization using `create_customization` immediately below. On success, when you ascertain the customization ID, set the `customization_id` variable below to it for use later in the notebook.\n",
    "\n",
    "In order to complete this task you'll need to pass `create_customization` the following arguments:\n",
    "- `model`: This should be a LoRA fine-tuneable GPT8B model. You can use the `LoraModels` enum provided above if you wish.\n",
    "- `training_dataset_file_id`: This should be the file ID returned to you above when you (mock) uploaded the training data to NeMo Service.\n",
    "- `validation_dataset_file_id`: This should be the file ID returned to you above when you (mock) uploaded the validation data to NeMo Service.\n",
    "- `adapter_dim`: Use the default value of `32`.\n",
    "- `epochs`: Train for 1 epoch.\n",
    "\n",
    "Worth mentioning is that since we are not providing `validation_data` explicity, NeMo Service will simply use 10% of the training data we provide for validation.\n",
    "\n",
    "If you get stuck, feel free to check out the *Solution* below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b49be-2732-4dc9-b02f-751bdc1a707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_customization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28bfe4-af69-4dda-9792-8f7e91d00db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customization_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c9921-3f4e-4a1d-970c-848fc6c894a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d14e05-9e5e-424f-aa13-1be26bbccb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_customization(model=LoraModels.gpt8b.value,\n",
    "                     training_dataset_file_id='f17e25cd-fd08-42b4-a508-12f48985be35',\n",
    "                     validation_dataset_file_id='30655aa3-17de-41b1-8d73-ddd4a3fadded',\n",
    "                     adapter_dim=32,\n",
    "                     epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615209a3-b463-4a98-b518-b260976d62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "customization_id = 'ebd552dc-a050-4987-afca-9136d45fbad1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1504bc87-42ea-4d8b-8b9d-d40b4dffa7f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c19a9e-e829-47c1-821b-6d4725d81217",
   "metadata": {},
   "source": [
    "## Perform Extractive QA with GPT8B LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895c4ceb-9d37-4f1f-a01c-bab472598a65",
   "metadata": {},
   "source": [
    "Next we will try the LoRA fine-tuned GPT8B model for the extractive QA task. First we create a model instance, using the LoRA GPT8B base model and providing the model customization ID ascertained from NeMo Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c598c-97e9-439d-908d-d1f720fcf8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt8b_lora = NemoServiceBaseModel(LoraModels.gpt8b.value, customization_id=customization_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b80f77b-8de1-4636-b3b6-fb9f45bf5096",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c7fba-82c5-4027-8e44-b7b078142044",
   "metadata": {},
   "source": [
    "Let's try a single QA prompt out on GPT8B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645878a-c3c9-4b14-8fd0-37251d55f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt, label = test_prompts_and_answers[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd6b66-cfcb-4880-bcd9-04ced8e827bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e03f92-649d-4104-890c-f3389ad5f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8382ce-26c4-4e01-bdd7-c03ad0d6938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt8b_lora.generate(prompt).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c23206-3578-440d-bb6a-5e96249a7203",
   "metadata": {},
   "source": [
    "At a glance it looks like the LoRA fine-tuned GPT8B model is doing well. Unlike in the previous notebook where we used just the base GPT8B model, this response does not go on and on, the answer looks to be extracted directly from the text, and is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9482c1be-4dec-4dee-9a7e-92aad4c257dd",
   "metadata": {},
   "source": [
    "### Try on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109cbfa9-4e77-4f79-9214-4ae77266341b",
   "metadata": {},
   "source": [
    "Now let's try the fine-tuned GPT8B model on the full test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972daa93-9897-4887-908f-2474e44c2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt, answer in test_prompts_and_answers:\n",
    "    response = gpt8b_lora.generate(prompt).strip()\n",
    "    print(f'Response: {response}')\n",
    "    print(f'Label: {answer}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ac838-dd6c-4117-80f7-47ad6bde2cab",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935df50-e097-4fcf-bb0f-4b219019f2d1",
   "metadata": {},
   "source": [
    "The LoRA fine-tuned GPT8B model is not peforming perfectly, however it is doing a relatively good job. At times its answers are incorrect, and it sometimes lists out its responses, but for the most part it is able to perform the task we would like. We will be interested to see how it peforms on the task we intend it for instead of responding to the SQuAD questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
