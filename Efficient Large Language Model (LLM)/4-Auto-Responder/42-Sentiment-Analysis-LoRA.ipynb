{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8f7516-57f9-471f-8bd9-b080127a688b",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da992d2-2293-4519-8ebb-5a856db69642",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LoRA for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb453e-7613-4dc9-9715-087799586a53",
   "metadata": {},
   "source": [
    "In this notebook you will fine tune GPT8B with LoRA to perform sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe72d8-f76e-4b44-80f2-c73b5ae6c7d5",
   "metadata": {},
   "source": [
    "![LoRA Sentiment](images/sentiment_lora.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f27af-228b-4e0e-b718-8345cb50f511",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acdf224-2849-43af-9265-e33d221b10b7",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e18c9-1f9e-4f67-8ad8-f5082c95b021",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will be able to:\n",
    "- LoRA fine tune a GPT8B model for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e084ec8-042a-456b-bdc9-457739a75344",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12ce63-7179-405b-86cf-03e49f51f354",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807cfa5-a29a-4e8b-ac92-063655341429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from llm_utils.models import LoraModels\n",
    "from llm_utils.nemo_service_models import NemoServiceBaseModel\n",
    "from llm_utils.mocks import upload_sentiment as upload\n",
    "from llm_utils.mocks import create_sentiment_lora_customization as create_customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b1c11-09be-40f1-aceb-09535d298f0b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c7df4-40ae-40dd-826c-93380de3c175",
   "metadata": {},
   "source": [
    "## List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14eaeea-5961-4bc1-87fd-90fa9bbc2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoraModels.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d25de-1012-4c43-9581-299bfb3aacd8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017a817-edab-4029-abb1-4ed21b094ffb",
   "metadata": {},
   "source": [
    "## Load Train Data From File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa695035-c087-4949-bd10-f7e3c3ac5ed4",
   "metadata": {},
   "source": [
    "We will begin this notebook by loading the train and test prompt and label data we created in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f847fdf-d8d1-4fa9-a1c0-370d489dbba9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a845d15-607a-49df-9180-f9484b45abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sentiment_prompts_labels_train_1500.json', 'r') as f:\n",
    "    train_prompts_with_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edecc43e-412b-4b22-a8c0-2e0f3e9b09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sentiment_prompts_labels_test_20.json', 'r') as f:\n",
    "    test_prompts_with_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e1e70-1342-4ebe-b074-3553f2177375",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_prompts_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cbbda0-05ad-4e5f-9b79-fde745ddfe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_prompts_with_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d783aa1-715b-4131-a0a5-8aed17c77e6d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d32ab3-1ef2-40da-87da-3b8347ef93f1",
   "metadata": {},
   "source": [
    "## Exercise: Format Data Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f11996-0036-4dc3-bb02-2c5438c5e4d8",
   "metadata": {},
   "source": [
    "For this exercise, you will format `train_prompts_with_labels` for NeMo Service fine tuning.\n",
    "\n",
    "As a reminder, NeMo Service expects that data be in JSON Lines (`jsonl`) format, with each line in the file being in the following format:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87165f3f-c21b-42f0-bb96-3605bb2e7224",
   "metadata": {},
   "source": [
    "```python\n",
    "{\"prompt\": <prompt>, \"completion\": <completion/label>}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f504a1-07e4-4b87-8ee3-48d5fdfb677f",
   "metadata": {},
   "source": [
    "Your task is to populate the `sentiment_lora_train_data` list with one dictionary for each data sample in `train_prompts_with_labels`, formatted as needed for NeMo Service LoRA fine-tuning.\n",
    "\n",
    "If you get stuck, feel free to look at the solution below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d5272-8820-4626-8222-a1012803bcc0",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228acbc5-ffef-400a-948d-e7b838d1115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lora_train_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047247c-e3e0-4202-b808-db0db008d5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40a09225-2b5c-493f-875a-fcdf50153b94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00233379-dffe-4221-97a9-4406e77b83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lora_train_data = [{'prompt': prompt, 'completion': label} for prompt, label in train_prompts_with_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6b5795-f302-49e7-ba3a-f9254730fdf2",
   "metadata": {},
   "source": [
    "Here we see an example of data well-formatted for LoRA fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c1d94-2f3e-4f7f-9a7f-46edc2809e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lora_train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6274e-7aaf-466a-ac31-49e193960edb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5861c0f6-a9b0-4e85-b3e5-e446ef90d89e",
   "metadata": {},
   "source": [
    "## Write Fine-tuning Data to File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b4d61-7592-418e-98ea-ed0e2603c5e7",
   "metadata": {},
   "source": [
    "Now we write `sentiment_lora_train_data` to file in JSON lines format, as is expected by NeMo Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40424fe-b6c0-4482-8a56-e7e55010de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_train_data_filename = 'data/sentiment_train_data_1500.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8654f3-ddc8-4be5-8b87-8dc150b830fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sentiment_train_data_filename, 'w') as f:\n",
    "    for d in sentiment_lora_train_data:\n",
    "        f.write(json.dumps(d) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c5f1e0-1c59-41b2-bab6-8abf918699d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbdffe4-4517-4f0a-b178-9def02fd1955",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a36016-6719-4481-8ff7-2ad47fa61982",
   "metadata": {},
   "source": [
    "## Upload Data to NeMo Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71659c-7d75-4a14-a199-2fdd512fa9cb",
   "metadata": {},
   "source": [
    "With the data written to file in JSON lines format, we can now upload it to NeMo Service. As we did earlier, we will mock this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8453ff-c20f-49f6-9b25-03f6ef61555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_response = upload(sentiment_train_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c912b4a-0d1a-453b-bcdd-9446208ac820",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a802b9-5b52-43d8-9511-ecaf245338bf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b910e3da-22ee-44d3-b782-00e4045809ff",
   "metadata": {},
   "source": [
    "## Exercise: LoRA Fine-tune GPT8B for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2dc0a-6580-431f-8b95-a5e286f63b33",
   "metadata": {},
   "source": [
    "For this exercise you will perform LoRA fine-tuning on GPT8B with the training data you just wrote to file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601468fe-6194-44bb-a0c6-12a4200469db",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe61bdd6-d5f4-44b4-a5c1-b295548ed993",
   "metadata": {},
   "source": [
    "Correctly launch a (mock) LoRA customization using `create_customization` immediately below. On success, when you ascertain the customization ID, set the `customization_id` variable below to it for use later in the notebook.\n",
    "\n",
    "In order to complete this task you'll need to pass `create_customization` the following arguments:\n",
    "- `model`: This should be a LoRA fine-tuneable GPT8B model. You can use the `LoraModels` enum provided above if you wish.\n",
    "- `training_dataset_file_id`: This should be the file ID returned to you above when you (mock) uploaded the training data to NeMo Service.\n",
    "- `adapter_dim`: Use the default value of `32`.\n",
    "- `epochs`: Train for 3 epochs.\n",
    "\n",
    "Worth mentioning is that since we are not providing `validation_data` explicity, NeMo Service will simply use 10% of the training data we provide for validation.\n",
    "\n",
    "If you get stuck, feel free to check out the *Solution* below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b49be-2732-4dc9-b02f-751bdc1a707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_customization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28bfe4-af69-4dda-9792-8f7e91d00db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customization_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c9921-3f4e-4a1d-970c-848fc6c894a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d14e05-9e5e-424f-aa13-1be26bbccb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_customization(model=LoraModels.gpt8b.value,\n",
    "                     training_dataset_file_id='8d55c2d8-c124-46bd-bbf6-864e22f2be9f',\n",
    "                     adapter_dim=32,\n",
    "                     epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615209a3-b463-4a98-b518-b260976d62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "customization_id = 'a8ddd3ab-f74b-40e6-972a-6c18c4690d7b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1504bc87-42ea-4d8b-8b9d-d40b4dffa7f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c19a9e-e829-47c1-821b-6d4725d81217",
   "metadata": {},
   "source": [
    "## Perform Sentiment Analysis with GPT8B LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895c4ceb-9d37-4f1f-a01c-bab472598a65",
   "metadata": {},
   "source": [
    "Next we will try the LoRA fine-tuned GPT8B model for the sentiment analysis task. First we create a model instance, using the LoRA GPT8B base model and providing the model customization ID ascertained from NeMo Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c598c-97e9-439d-908d-d1f720fcf8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt8b_lora = NemoServiceBaseModel(LoraModels.gpt8b.value, customization_id='a8ddd3ab-f74b-40e6-972a-6c18c4690d7b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b80f77b-8de1-4636-b3b6-fb9f45bf5096",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c7fba-82c5-4027-8e44-b7b078142044",
   "metadata": {},
   "source": [
    "Let's try a single sentiment analysis prompt out on GPT8B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645878a-c3c9-4b14-8fd0-37251d55f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt, label = test_prompts_with_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e03f92-649d-4104-890c-f3389ad5f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8382ce-26c4-4e01-bdd7-c03ad0d6938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt8b_lora.generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbccedf-b23d-4ac9-a387-5b13067a602c",
   "metadata": {},
   "source": [
    "Unlike the zero-shot prompt in the previous notbook with just the base GPT8B model, the model did not go on at length after providing the sentiment, and the response, except for some white space, appears to be formatted exactly like we would like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9482c1be-4dec-4dee-9a7e-92aad4c257dd",
   "metadata": {},
   "source": [
    "### Try on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109cbfa9-4e77-4f79-9214-4ae77266341b",
   "metadata": {},
   "source": [
    "Now let's try the fine-tuned GPT8B model on the full test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972daa93-9897-4887-908f-2474e44c2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "num_samples = len(test_prompts_with_labels)\n",
    "for prompt, label in test_prompts_with_labels:\n",
    "    response = gpt8b_lora.generate(prompt).strip()\n",
    "    is_correct = response == label\n",
    "    if is_correct:\n",
    "        num_correct += 1\n",
    "    print(f'Response: {response}')\n",
    "    print(f'Label: {label}')\n",
    "    print(f'Is Correct: {response == label}\\n')\n",
    "\n",
    "print(f'Number Correct: {num_correct}/{num_samples}')\n",
    "print(f'Percentage Correct: {num_correct / num_samples*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ac838-dd6c-4117-80f7-47ad6bde2cab",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935df50-e097-4fcf-bb0f-4b219019f2d1",
   "metadata": {},
   "source": [
    "The LoRA fine-tuned GPT8B model scored perfectly on the test set, even better than the zero-shot, and much larger GPT43B did. This is a huge model size reduction, and without the need for any example shots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
